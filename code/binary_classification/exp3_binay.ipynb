{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exp3_binay.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4035,"status":"ok","timestamp":1650303693223,"user":{"displayName":"xiang gao","userId":"18056195333349536450"},"user_tz":240},"id":"hV3OfnRxglel","outputId":"b108f0f6-9c4e-47dc-9483-d6e11e35c884"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/Shareddrives/EECS 545 Project/5DE/lane-detection-2019-howard')"],"metadata":{"id":"sM6qOXiJK2hf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","class UNetFactory(nn.Module):\n","    \"\"\"\n","    本质上就是一个U型的网络，先encode，后decode，中间可能有架bridge。\n","    其中encoder需要输出skip到decode那边做concatenate，使得decode阶段能补充信息。\n","    bridge不能存在下采样和上采样的操作。\n","    \"\"\"\n","    def __init__(self, encoder_blocks, decoder_blocks, bridge=None):\n","        super(UNetFactory, self).__init__()\n","        self.encoder = UNetEncoder(encoder_blocks)\n","        self.bridge = bridge\n","        self.decoder = UNetDecoder(decoder_blocks)\n","\n","    def forward(self, x):\n","        res = self.encoder(x)\n","        out, skips = res[0], res[1:]\n","        if self.bridge is not None:\n","            out = self.bridge(out)\n","        out = self.decoder(out, skips)\n","        return out\n","\n","class UNetEncoder(nn.Module):\n","    \"\"\"\n","    encoder会有多次下采样，下采样前的feature map要作为skip缓存起来将来送到decoder用。\n","    这里约定，以下采样为界线，将encoder分成多个block，其中第一个block无下采样操作，后面的每个block内都\n","    含有一次下采样操作。\n","    \"\"\"\n","    def __init__(self, blocks):\n","        super(UNetEncoder, self).__init__()\n","        assert len(blocks) > 0\n","        self.blocks = nn.ModuleList(blocks)\n","\n","    def forward(self, x):\n","        skips = []\n","        for i in range(len(self.blocks) - 1):\n","            x = self.blocks[i](x)\n","            skips.append(x)\n","        res = [self.blocks[i+1](x)]\n","        res += skips\n","        return res # 只能以这种方式返回多个tensor\n","\n","class UNetDecoder(nn.Module):\n","    \"\"\"\n","    decoder会有多次上采样，每次上采样后，要跟相应的skip做concatenate。\n","    这里约定，以上采样为界线，将decoder分成多个block，其中最后一个block无上采样操作，其他block内\n","    都含有一次上采样。如此一来，除第一个block以外，其他block都先做concatenate。\n","    \"\"\"\n","    def __init__(self, blocks):\n","        super(UNetDecoder, self).__init__()\n","        assert len(blocks) > 1\n","        self.blocks = nn.ModuleList(blocks)\n","    \n","    def _center_crop(self, skip, x):\n","        \"\"\"\n","        skip和x，谁比较大，就裁剪谁\n","        \"\"\"\n","        _, _, h1, w1 = skip.shape\n","        _, _, h2, w2 = x.shape\n","        ht, wt = min(h1, h2), min(w1, w2)\n","        dh1 = (h1 - ht) // 2 if h1 > ht else 0\n","        dw1 = (w1 - wt) // 2 if w1 > wt else 0\n","        dh2 = (h2 - ht) // 2 if h2 > ht else 0\n","        dw2 = (w2 - wt) // 2 if w2 > wt else 0\n","        return skip[:, :, dh1: (dh1 + ht), dw1: (dw1 + wt)], \\\n","                x[:, :, dh2: (dh2 + ht), dw2: (dw2 + wt)]\n","\n","    def forward(self, x, skips, reverse_skips=True):\n","        assert len(skips) == len(self.blocks) - 1\n","        if reverse_skips:\n","            skips = skips[::-1]\n","        x = self.blocks[0](x)\n","        for i in range(1, len(self.blocks)):\n","            skip, x = self._center_crop(skips[i-1], x)\n","            x = torch.cat([skip, x], dim=1)\n","            x = self.blocks[i](x)\n","        return x\n","\n","def unet_convs(in_channels, out_channels, padding=0):\n","    \"\"\"\n","    unet论文里出现次数最多的2个conv3x3(non-padding)的结构\n","    \"\"\"\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding, bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","\n","def unet(in_channels, out_channels):\n","    \"\"\"\n","    构造跟论文一致的unet网络\n","    https://arxiv.org/abs/1505.04597\n","    \"\"\"\n","    # encoder\n","    encoder_blocks = [\n","        # two conv3x3\n","        unet_convs(in_channels, 64),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(64, 128)\n","        ),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(128, 256)\n","        ),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(256, 512)\n","        ),\n","        # max pool 2x2\n","        nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n","    ]\n","    # bridge\n","    bridge = nn.Sequential(\n","        # two conv3x3\n","        unet_convs(512, 1024)\n","    )\n","    # decoder\n","    decoder_blocks = [\n","        # up-conv2x2\n","        nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(1024, 512),\n","            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(512, 256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(256, 128),\n","            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, conv1x1\n","        nn.Sequential(\n","            unet_convs(128, 64),\n","            nn.Conv2d(64, out_channels, kernel_size=1)\n","        )\n","    ]\n","    return UNetFactory(encoder_blocks, decoder_blocks, bridge)\n","\n","def unet_resnet(resnet_type, in_channels, out_channels, pretrained=True):\n","    \"\"\"\n","    利用resnet作为encoder，相应地，decoder也做一些改动，使得输出的尺寸跟原始的一致\n","    \"\"\"\n","    if resnet_type == 'resnet18':\n","        resnet = torchvision.models.resnet.resnet18(pretrained)\n","        encoder_out_channels = [in_channels, 64, 64, 128, 256, 512]  # encoder各个block的输出channel\n","    elif resnet_type == 'resnet34':\n","        resnet = torchvision.models.resnet.resnet34(pretrained)\n","        encoder_out_channels = [in_channels, 64, 64, 128, 256, 512]\n","    elif resnet_type == 'resnet50':\n","        resnet = torchvision.models.resnet.resnet50(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnet101':\n","        resnet = torchvision.models.resnet.resnet101(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnet152':\n","        resnet = torchvision.models.resnet.resnet152(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnext50_32x4d':\n","        resnet = torchvision.models.resnet.resnext50_32x4d(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    else:\n","        raise ValueError(\"unexpected resnet_type\")\n","\n","    # encoder\n","    encoder_blocks = [\n","        # org input\n","        nn.Sequential(),\n","        # conv1\n","        nn.Sequential(\n","            resnet.conv1,\n","            resnet.bn1,\n","            resnet.relu\n","        ),\n","        # conv2_x\n","        nn.Sequential(\n","            resnet.maxpool,\n","            resnet.layer1\n","        ),\n","        # conv3_x\n","        resnet.layer2,\n","        # conv4_x\n","        resnet.layer3,\n","        # conv5_x\n","        resnet.layer4\n","    ]\n","    # bridge\n","    bridge = None  # 感觉并无必要\n","    # decoder\n","    decoder_blocks = []\n","    in_ch = encoder_out_channels[-1]\n","    out_ch = in_ch // 2\n","    decoder_blocks.append(nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)) # up-conv2x2\n","    for i in range(1, len(encoder_blocks)-1):\n","        in_ch = encoder_out_channels[-i-1] + out_ch  # cat\n","        decoder_blocks.append(nn.Sequential(  # two conv3x3, up-conv2x2\n","            unet_convs(in_ch, out_ch, padding=1),\n","            nn.ConvTranspose2d(out_ch, out_ch//2, kernel_size=2, stride=2),\n","        ))\n","        out_ch = out_ch // 2\n","    in_ch = encoder_out_channels[0] + out_ch  # cat\n","    decoder_blocks.append(nn.Sequential(  # two conv3x3, conv1x1\n","        unet_convs(in_ch, out_ch, padding=1),\n","        nn.Conv2d(out_ch, out_channels, kernel_size=1)\n","    ))\n","\n","    return UNetFactory(encoder_blocks, decoder_blocks, bridge)"],"metadata":{"id":"MDTNSK_bQCqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_gray_label(labels):\n","    \"\"\"\n","    将标签图的灰度值转换成类别id\n","    注意：ignoreInEval为True的都当分类0处理\n","    @param labels: 标签灰度图\n","    \"\"\"\n","    encoded_labels = np.zeros_like(labels)\n","    # 除了下面特意转换的，其余都属于类别0\n","    # 1\n","    encoded_labels[labels == 200] = 1\n","    encoded_labels[labels == 204] = 1\n","    encoded_labels[labels == 209] = 1\n","    # 2\n","    encoded_labels[labels == 201] = 0\n","    encoded_labels[labels == 203] = 0\n","    # 3\n","    encoded_labels[labels == 217] = 0\n","    # 4\n","    encoded_labels[labels == 210] = 0\n","    # 5\n","    encoded_labels[labels == 214] = 0\n","    # 6\n","    encoded_labels[labels == 220] = 0\n","    encoded_labels[labels == 221] = 0\n","    encoded_labels[labels == 222] = 0\n","    encoded_labels[labels == 224] = 0\n","    encoded_labels[labels == 225] = 0\n","    encoded_labels[labels == 226] = 0\n","    # 7\n","    encoded_labels[labels == 205] = 0\n","    encoded_labels[labels == 227] = 0\n","    encoded_labels[labels == 250] = 0\n","    return encoded_labels\n","def train_data_generator(image_list, label_list, batch_size, out_size, height_crop_offset):\n","    \"\"\"\n","    训练数据生成器\n","    :@param image_list: 图片文件的绝对地址\n","    :@param label_list: 标签文件的绝对地址\n","    :@param batch_size: 每批取多少张图片\n","    :@param image_size: 输出的图片尺寸\n","    :@param crop_offset: 在高度的方向上，将原始图片截掉多少\n","    \"\"\"\n","    indices = np.arange(0, len(image_list))  # 索引\n","    out_images = []\n","    out_labels = []\n","    out_images_filename = []\n","    while True:  # 可以无限生成\n","        np.random.shuffle(indices)\n","        for i in indices:\n","            try:\n","                image = cv2.imread(image_list[i])\n","                labels = cv2.imread(label_list[i], cv2.IMREAD_GRAYSCALE)\n","            except:\n","                continue\n","            # crop & resize\n","            image, labels = crop_resize_data(image, labels, out_size, height_crop_offset)\n","            # encode\n","            labels = encode_gray_label(labels)\n","\n","            ## data argumentation here \n","            \n","            out_images.append(image)\n","            out_labels.append(labels)\n","            out_images_filename.append(image_list[i])\n","            if len(out_images) == batch_size:\n","                out_images = np.array(out_images, dtype=np.float32)\n","                out_labels = np.array(out_labels, dtype=np.int64)\n","                # 转换成RGB\n","                out_images = out_images[:, :, :, ::-1]\n","                # 维度改成 (n, c, h, w)\n","                out_images = out_images.transpose(0, 3, 1, 2)\n","                # 归一化 -1 ~ 1\n","                out_images = out_images*2/255 - 1\n","                yield torch.from_numpy(out_images), torch.from_numpy(out_labels).long(), out_images_filename\n","                out_images = []\n","                out_labels = []\n","                out_images_filename = []\n","def crop_resize_data(image, labels, out_size, height_crop_offset):\n","    \"\"\"\n","    @param out_size: (w, h)\n","    \"\"\"\n","    roi_image = image[height_crop_offset:] # crop\n","    roi_image = cv2.resize(roi_image, out_size, interpolation=cv2.INTER_LINEAR)  # resize\n","    if labels is not None:\n","        roi_label = labels[height_crop_offset:]\n","        roi_label = cv2.resize(roi_label, out_size, interpolation=cv2.INTER_NEAREST)  # label必须用最近邻来，因为每个像素值是一个分类id\n","    else:\n","        roi_label = None\n","    return roi_image, roi_label\n"],"metadata":{"id":"rUbpIzPCRmNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","@description: Configure Class \n","\"\"\"\n","\n","from os.path import join as pjoin\n","from os.path import dirname, abspath\n","import torch\n","\n","class ConfigTrain(object):\n","    # 目录\n","    PROJECT_ROOT = \"/content/drive/Shareddrives/EECS 545 Project/5DE/lane-detection-2019-howard\"\n","    DATA_LIST_ROOT = pjoin(PROJECT_ROOT, 'data_list')\n","    TRAIN_ROOT = \"/content/drive/Shareddrives/EECS 545 Project/data\"\n","    IMAGE_ROOT = pjoin(TRAIN_ROOT, 'Image_Data')\n","    LABEL_ROOT = pjoin(TRAIN_ROOT, 'Gray_Label')\n","    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'binary_classification','weights')\n","    WEIGHTS_SAVE_ROOT = WEIGHTS_ROOT\n","    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\n","\n","    # log文件\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b1.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b4.log')\n","    LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b2.log')\n","\n","    # 设备\n","    DEVICE = 'cuda:0' \n","    \n","    if torch.cuda.is_available():\n","      print(\"Using the GPU. You are good to go!\")\n","      DEVICE = 'cuda'\n","    else:\n","      print(\"Using the CPU. Overall speed may be slowed down\")\n","      DEVICE = 'cpu'\n","    \n","    # 网络类型\n","    NET_NAME = 'unet_resnet101'\n","    #NET_NAME = 'resnext50_32x4d'\n","    # 网络参数\n","    NUM_CLASSES = 2  # 8个类别\n","    IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\n","    # IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\n","    #IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\n","    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\n","    # BATCH_SIZE = 8  # 数据批次大小\n","    # BATCH_SIZE = 1  # 数据批次大小\n","    # BATCH_SIZE = 4  # 数据批次大小\n","    BATCH_SIZE = 8  # 数据批次大小\n","    EPOCH_NUM = 8  # 总轮次\n","    PRETRAIN = False # 是否加载预训练的权重\n","    EPOCH_BEGIN = 0  # 接着前面的epoch训练，默认0，表示从头训练\n","    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'result_6.pt')\n","    BASE_LR = 0.001  # 学习率\n","    LR_STRATEGY = [\n","        [0.001], # epoch 0\n","        [0.001], # epoch 1\n","        [0.001], # epoch 2\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 3\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 4\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 5\n","        [0.0004, 0.0003, 0.0002, 0.0001, 0.0002, 0.0003, 0.0004], # epoch 6\n","        [0.0004, 0.0003, 0.0002, 0.0001, 0.0002, 0.0003, 0.0004], # epoch 7\n","    ]\n","    SUSPICIOUS_RATE = 0.8  # 可疑比例：当某个iteration的miou比当前epoch_miou的可疑比例还要小的时候，记录此次iteration的训练数据索引，人工排查是否数据有问题\n","\n","## TO DO: Define PROJECT_ROOT##\n","'''    \n","class ConfigInference(object):\n","    # 目录\n","    PROJECT_ROOT = dirname(abspath(__file__)) \n","    DATA_ROOT = pjoin(PROJECT_ROOT, 'data')\n","    IMAGE_ROOT = pjoin(DATA_ROOT, 'TestImage')\n","    LABEL_ROOT = pjoin(DATA_ROOT, 'TestLabel')\n","    OVERLAY_ROOT = pjoin(DATA_ROOT, 'TestOverlay')\n","    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'weights')\n","    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'resnext50_32x4d-7cdf4587.pth')\n","    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\n","\n","    # 设备\n","    DEVICE = 'cuda:0'\n","\n","    # 网络类型\n","    NET_NAME = 'resnext50_32x4d'\n","\n","    # 网络参数\n","    NUM_CLASSES = 8  # 8个类别\n","    # IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\n","    IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\n","    # IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\n","    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\n","    BATCH_SIZE = 1  # 数据批次大小\n","\n","    # 原图的大小\n","    IMAGE_SIZE_ORG = (3384, 1710)\n","'''    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"dha6U_LzGxtJ","executionInfo":{"status":"ok","timestamp":1650303694046,"user_tz":240,"elapsed":20,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}},"outputId":"430ac6f0-188e-401a-aed6-0e8adb11b785"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using the GPU. You are good to go!\n"]},{"output_type":"execute_result","data":{"text/plain":["\"    \\nclass ConfigInference(object):\\n    # 目录\\n    PROJECT_ROOT = dirname(abspath(__file__)) \\n    DATA_ROOT = pjoin(PROJECT_ROOT, 'data')\\n    IMAGE_ROOT = pjoin(DATA_ROOT, 'TestImage')\\n    LABEL_ROOT = pjoin(DATA_ROOT, 'TestLabel')\\n    OVERLAY_ROOT = pjoin(DATA_ROOT, 'TestOverlay')\\n    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'weights')\\n    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'resnext50_32x4d-7cdf4587.pth')\\n    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\\n\\n    # 设备\\n    DEVICE = 'cuda:0'\\n\\n    # 网络类型\\n    NET_NAME = 'resnext50_32x4d'\\n\\n    # 网络参数\\n    NUM_CLASSES = 8  # 8个类别\\n    # IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\\n    IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\\n    # IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\\n    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\\n    BATCH_SIZE = 1  # 数据批次大小\\n\\n    # 原图的大小\\n    IMAGE_SIZE_ORG = (3384, 1710)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["'''\n","Define loss\n","'''\n","class MySoftmaxCrossEntropyLoss(nn.Module):\n","\n","    def __init__(self, nbclasses):\n","        super(MySoftmaxCrossEntropyLoss, self).__init__()\n","        self.nbclasses = nbclasses\n","\n","    def forward(self, inputs, target):\n","        if inputs.dim() > 2:\n","            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n","            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n","            inputs = inputs.contiguous().view(-1, self.nbclasses)  # N,H*W,C => N*H*W,C\n","        target = target.view(-1)\n","        return nn.CrossEntropyLoss(reduction=\"mean\")(inputs, target)\n","\n","\n","class FocalLoss(nn.Module):\n","\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.alpha = torch.tensor([alpha, 1 - alpha])\n","        self.size_average = size_average\n","\n","    def forward(self, inputs, target):\n","        if inputs.dim() > 2:\n","            inputs = inputs\n","            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n","            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n","            inputs = inputs.contiguous().view(-1, inputs.size(2))  # N,H*W,C => N*H*W,C\n","        target = target.view(-1, 1)\n","\n","        logpt = F.log_softmax(inputs,dim=1)\n","        logpt = logpt.gather(1, target)\n","        logpt = logpt.view(-1)\n","        pt = logpt.exp()\n","\n","        if self.alpha is not None:\n","            if self.alpha.type() != inputs.data.type():\n","                self.alpha = self.alpha.type_as(inputs.data)\n","            at = self.alpha.gather(0, target.view(-1))\n","            logpt = logpt * at\n","        # mask = mask.view(-1)\n","        loss = -1 * (1 - pt) ** self.gamma * logpt #* mask\n","        if self.size_average:\n","            return loss.mean()\n","        else:\n","            return loss.sum()\n","\n","\n","def make_one_hot(input, num_classes):\n","    \"\"\"Convert class index tensor to one hot encoding tensor.\n","    Args:\n","         input: A tensor of shape [N, 1, *]\n","         num_classes: An int of number of class\n","    Returns:\n","        A tensor of shape [N, num_classes, *]\n","    \"\"\"\n","    shape = np.array(input.shape)\n","    shape[1] = num_classes\n","    shape = tuple(shape)\n","    result = torch.zeros(shape)\n","    result = result.scatter_(1, input.cpu(), 1)\n","\n","    return result\n","\n","\n","class BinaryDiceLoss(nn.Module):\n","    \"\"\"Dice loss of binary class\n","    Args:\n","        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n","        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n","        predict: A tensor of shape [N, *]\n","        target: A tensor of shape same with predict log文件\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b1.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b4.log')\n","    LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b2.log')\n","        reduction: Reduction method to apply, return mean over batch if 'mean',\n","            return sum if 'sum', return a tensor of shape [N,] if 'none'\n","    Returns:\n","        Loss tensor according to arg reduction\n","    Raise:\n","        Exception if unexpected reduction\n","    \"\"\"\n","    def __init__(self, smooth=1, p=2, reduction='mean'):\n","        super(BinaryDiceLoss, self).__init__()\n","        self.smooth = smooth\n","        self.p = p\n","        self.reduction = reduction\n","\n","    def forward(self, predict, target):\n","        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n","        predict = predict.contiguous().view(predict.shape[0], -1)\n","        target = target.contiguous().view(target.shape[0], -1)\n","        num = 2*torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n","        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n","\n","        loss = 1 - num / den\n","\n","        if self.reduction == 'mean':\n","            return loss.mean()\n","        elif self.reduction == 'sum':\n","            return loss.sum()\n","        elif self.reduction == 'none':\n","            return loss\n","        else:\n","            raise Exception('Unexpected reduction {}'.format(self.reduction))\n","\n","\n","class DiceLoss(nn.Module):\n","    \"\"\"Dice loss, need one hot encode input\n","    Args:\n","        weight: An array of shape [num_classes,]\n","        ignore_index: class index to ignore\n","        predict: A tensor of shape [N, C, *]\n","        target: A tensor of same shape with predict\n","        other args pass to BinaryDiceLoss\n","    Return:\n","        same as BinaryDiceLoss\n","    \"\"\"\n","    def __init__(self, weight=None, ignore_index=None, **kwargs):\n","        super(DiceLoss, self).__init__()\n","        self.kwargs = kwargs\n","        self.weight = weight\n","        self.ignore_index = ignore_index\n","\n","    def forward(self, predict, target):\n","        assert predict.shape == target.shape, 'predict & target shape do not match'\n","        dice = BinaryDiceLoss(**self.kwargs)\n","        total_loss = 0\n","        predict = F.softmax(predict, dim=1)\n","\n","        for i in range(target.shape[1]):\n","            if i != self.ignore_index:\n","                dice_loss = dice(predict[:, i], target[:, i])\n","                if self.weight is not None:\n","                    assert self.weight.shape[0] == target.shape[1], \\\n","                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n","                    dice_loss *= self.weights[i]\n","                total_loss += dice_loss\n","\n","        return total_loss/target.shape[1]\n","\n"],"metadata":{"id":"VhCWX0QNWYYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\"\"\"\n","Lovasz-Softmax and Jaccard hinge loss in PyTorch\n","Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n","\"\"\"\n","\n","from __future__ import print_function, division\n","\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","try:\n","    from itertools import  ifilterfalse\n","except ImportError: # py3k\n","    from itertools import  filterfalse as ifilterfalse\n","\n","\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    p = len(gt_sorted)\n","    gts = gt_sorted.sum()\n","    intersection = gts - gt_sorted.float().cumsum(0)\n","    union = gts + (1 - gt_sorted).float().cumsum(0)\n","    jaccard = 1. - intersection / union\n","    if p > 1: # cover 1-pixel case\n","        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n","    return jaccard\n","\n","\n","def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n","    \"\"\"\n","    IoU for foreground class\n","    binary: 1 foreground, 0 background\n","    \"\"\"\n","    if not per_image:\n","        preds, labels = (preds,), (labels,)\n","    ious = []\n","    for pred, label in zip(preds, labels):\n","        intersection = ((label == 1) & (pred == 1)).sum()\n","        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n","        if not union:\n","            iou = EMPTY\n","        else:\n","            iou = float(intersection) / float(union)\n","        ious.append(iou)\n","    iou = mean(ious)    # mean accross images if per_image\n","    return 100 * iou\n","\n","\n","def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n","    \"\"\"\n","    Array of IoU for each (non ignored) class\n","    \"\"\"\n","    if not per_image:\n","        preds, labels = (preds,), (labels,)\n","    ious = []\n","    for pred, label in zip(preds, labels):\n","        iou = []    \n","        for i in range(C):\n","            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n","                intersection = ((label == i) & (pred == i)).sum()\n","                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n","                if not union:\n","                    iou.append(EMPTY)\n","                else:\n","                    iou.append(float(intersection) / float(union))\n","        ious.append(iou)\n","    ious = [mean(iou) for iou in zip(*ious)] # mean accross images if per_image\n","    return 100 * np.array(ious)\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                          for log, lab in zip(logits, labels))\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","    if len(labels) == 0:\n","        # only void pixels, the gradients should be 0\n","        return logits.sum() * 0.\n","    signs = 2. * labels.float() - 1.\n","    errors = (1. - logits * Variable(signs))\n","    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n","    perm = perm.data\n","    gt_sorted = labels[perm]\n","    grad = lovasz_grad(gt_sorted)\n","    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = scores.view(-1)\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return scores, labels\n","    valid = (labels != ignore)\n","    vscores = scores[valid]\n","    vlabels = labels[valid]\n","    return vscores, vlabels\n","\n","\n","class StableBCELoss(torch.nn.modules.Module):\n","    def __init__(self):\n","         super(StableBCELoss, self).__init__()\n","    def forward(self, input, target):\n","         neg_abs = - input.abs()\n","         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n","         return loss.mean()\n","\n","\n","def binary_xloss(logits, labels, ignore=None):\n","    \"\"\"\n","    Binary Cross entropy loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      ignore: void class id\n","    \"\"\"\n","    logits, labels = flatten_binary_scores(logits, labels, ignore)\n","    loss = StableBCELoss()(logits, Variable(labels.float()))\n","    return loss\n","\n","\n","# --------------------------- MULTICLASS LOSSES ---------------------------\n","\n","\n","def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n","              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n","      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n","      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class labels\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n","                          for prob, lab in zip(probas, labels))\n","    else:\n","        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n","    return loss\n","\n","\n","def lovasz_softmax_flat(probas, labels, classes='present'):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n","      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n","    \"\"\"\n","    if probas.numel() == 0:\n","        # only void pixels, the gradients should be 0\n","        return probas * 0.\n","    C = probas.size(1)\n","    losses = []\n","    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n","    for c in class_to_sum:\n","        fg = (labels == c).float() # foreground for class c\n","        if (classes is 'present' and fg.sum() == 0):\n","            continue\n","        if C == 1:\n","            if len(classes) > 1:\n","                raise ValueError('Sigmoid output possible only with 1 class')\n","            class_pred = probas[:, 0]\n","        else:\n","            class_pred = probas[:, c]\n","        errors = (Variable(fg) - class_pred).abs()\n","        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n","        perm = perm.data\n","        fg_sorted = fg[perm]\n","        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n","    return mean(losses)\n","\n","\n","def flatten_probas(probas, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch\n","    \"\"\"\n","    if probas.dim() == 3:\n","        # assumes output of a sigmoid layer\n","        B, H, W = probas.size()\n","        probas = probas.view(B, 1, H, W)\n","    B, C, H, W = probas.size()\n","    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return probas, labels\n","    valid = (labels != ignore)\n","    vprobas = probas[valid.nonzero().squeeze()]\n","    vlabels = labels[valid]\n","    return vprobas, vlabels\n","\n","def xloss(logits, labels, ignore=None):\n","    \"\"\"\n","    Cross entropy loss\n","    \"\"\"\n","    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n","\n","\n","# --------------------------- HELPER FUNCTIONS ---------------------------\n","def isnan(x):\n","    return x != x\n","    \n","    \n","def mean(l, ignore_nan=False, empty=0):\n","    \"\"\"\n","    nanmean compatible with generators.\n","    \"\"\"\n","    l = iter(l)\n","    if ignore_nan:\n","        l = ifilterfalse(isnan, l)\n","    try:\n","        n = 1\n","        acc = next(l)\n","    except StopIteration:\n","        if empty == 'raise':\n","            raise ValueError('Empty mean')\n","        return empty\n","    for n, v in enumerate(l, 2):\n","        acc += v\n","    if n == 1:\n","        return acc\n","    return acc / n"],"metadata":{"id":"EAFofjy4ekge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","util files\n","'''\n","def create_net(in_channels, out_channels, net_name='unet'):\n","    \"\"\"\n","    创建网络\n","    :param in_channels: 输入通道数\n","    :param out_channels: 输出通道数\n","    # :param net_name: 网络类型，可选 unet | unet_resnet18/34/50/101/152 |unet_resnext50_32x4d | deeplabv3p\n","    :param net_name: 网络类型，可选 unet | unet_resnet34\n","    \"\"\"\n","    if net_name == 'unet':\n","        net = unet(in_channels, out_channels)\n","    elif net_name == 'unet_resnet34':\n","        net = unet_resnet('resnet34', in_channels, out_channels)\n","    elif net_name == 'unet_resnet50':\n","        net = unet_resnet('resnet50', in_channels, out_channels)\n","    elif net_name == 'unet_resnet101':\n","        net = unet_resnet('resnet101', in_channels, out_channels)    \n","    elif net_name == 'resnext50_32x4d':\n","        net = unet_resnet('resnext50_32x4d', in_channels, out_channels)\n","    else:\n","        raise ValueError('Not supported net_name: {}'.format(net_name))\n","\n","    return net\n","\n","def create_loss(predicts: torch.Tensor, labels: torch.Tensor, num_classes):\n","    \"\"\"\n","    创建loss\n","    @param predicts: shape=(n, c, h, w)\n","    @param labels: shape=(n, h, w) or shape=(n, 1, h, w)\n","    @param num_classes: int should equal to channels of predicts\n","    @return: loss, mean_iou\n","    \"\"\"\n","    # permute to (n, h, w, c)\n","    predicts = predicts.permute((0, 2, 3, 1))\n","    # reshape to (-1, num_classes)  每个像素在每种分类上都有一个概率\n","    predicts = predicts.reshape((-1, num_classes))\n","    ##print(predicts.shape)\n","    ##print(labels.flatten().shape)\n","    # BCE with DICE\n","    bce_loss = F.cross_entropy(predicts, labels.flatten(), reduction='mean')  # 函数内会自动做softmax\n","    \n","    # 将labels做one_hot处理，得到的形状跟predicts相同\n","    labels_one_hot = utils.make_one_hot(labels.reshape((-1, 1)), num_classes)\n","    dice_loss = utils.DiceLoss()(predicts, labels_one_hot.to(labels.device))  # torch没有原生的，从老师给的代码里拿过来用\n","    #loss = bce_loss + dice_loss\n","    loss = bce_loss\n","    ious = compute_iou(predicts, labels.reshape((-1, 1)), num_classes)\n","    return loss, torch.mean(ious)\n","\n","def compute_iou(predicts, labels, num_classes):\n","    \"\"\"\n","    计算iou\n","    @param predicts: shape=(-1, classes)\n","    @param labels: shape=(-1, 1)\n","    \"\"\"\n","    ious = torch.zeros(num_classes)\n","    predicts = F.softmax(predicts, dim=1)\n","    predicts = torch.argmax(predicts, dim=1, keepdim=True)\n","    for i in range(num_classes):\n","        intersect = torch.sum((predicts == i) * (labels == i))\n","        area = torch.sum(predicts == i) + torch.sum(labels == i) - intersect\n","        ious[i] = intersect / (area + 1e-6)\n","    return ious\n"],"metadata":{"id":"b7tOt0NiQTyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"y2sty2Y2Zx9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","@description: 执行训练\n","\"\"\"\n","\n","\n","\"\"\"\n","import\n","\"\"\"\n","#from config import ConfigTrain\n","import utils\n","from os.path import join as pjoin\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import torch\n","import time\n","\n","\"\"\"\n","main\n","\"\"\"\n","from tqdm import tqdm\n","if __name__ == '__main__':\n","    cfg = ConfigTrain()\n","    print('Pick device: ', cfg.DEVICE)\n","    device = torch.device(cfg.DEVICE)\n","\n","    # 网络\n","    print('Generating net: ', cfg.NET_NAME)\n","    net = create_net(3, cfg.NUM_CLASSES, net_name=cfg.NET_NAME)\n","    if cfg.PRETRAIN:  # 加载预训练权重\n","        print('Load pretrain weights: ', cfg.PRETRAINED_WEIGHTS)\n","        net.load_state_dict(torch.load(cfg.PRETRAINED_WEIGHTS, map_location='cpu'))\n","    net.to(device)\n","    # 优化器\n","    optimizer = torch.optim.Adam(net.parameters(), lr=cfg.BASE_LR) \n","\n","    # 训练数据生成器\n","    print('Preparing data... batch_size: {}, image_size: {}, crop_offset: {}'.format(cfg.BATCH_SIZE, cfg.IMAGE_SIZE, cfg.HEIGHT_CROP_OFFSET))\n","    df_train = pd.read_csv(pjoin(cfg.DATA_LIST_ROOT, 'train_split.csv'))\n","    data_generator = train_data_generator(np.array(df_train['image']),\n","                                                np.array(df_train['label']),\n","                                                cfg.BATCH_SIZE, cfg.IMAGE_SIZE, cfg.HEIGHT_CROP_OFFSET)\n","\n","    # 训练\n","    print('Let us train ...')\n","    log_iters = 1  # 多少次迭代打印一次log\n","    epoch_size = int(len(df_train) / cfg.BATCH_SIZE)  # 一个轮次包含的迭代次数\n","    ##trn_loss_hist = []\n","    ##iou_hist = []\n","    loss_plot = []\n","    iou_plot = []\n","    for epoch in range(cfg.EPOCH_BEGIN, cfg.EPOCH_NUM):\n","        epoch_loss = 0.0\n","        epoch_miou = 0.0\n","        last_epoch_miou = 0.0\n","        prev_time = time.time()\n","        for iteration in tqdm(range(1 , epoch_size + 1)):\n","            images, labels, images_filename = next(data_generator)\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            lr = utils.ajust_learning_rate(optimizer, cfg.LR_STRATEGY, epoch, iteration-1, epoch_size)\n","\n","            predicts = net(images)\n","\n","            optimizer.zero_grad()\n","\n","            # create loss\n","            cross_loss, mean_iou = utils.create_loss(predicts, labels, cfg.NUM_CLASSES)\n","            #iou = utils.iou(predicts, labels, 3,ignore=255, per_image=True)\n","            predicts =  torch.nn.functional.softmax(predicts,dim=1)\n","            #f_loss = focal_loss(predicts,labels)\n","            \n","            loss_lovasz_softmax = utils.lovasz_softmax(predicts, labels)\n","            loss = cross_loss + loss_lovasz_softmax\n","\n","            epoch_loss += loss.item()\n","            epoch_miou += mean_iou.item()\n","\n","            print(\"[Epoch-%d Iter-%d] LR: %.4f: iter loss: %.3f, iter iou: %.3f, epoch loss: %.3f, epoch iou: %.3f,  time cost: %.3f s\"\n","                % (epoch, iteration, lr, loss.item(), mean_iou.item(), epoch_loss / iteration, epoch_miou / iteration, time.time() - prev_time))\n","            prev_time = time.time()\n","\n","            # if mean_iou.item() < last_epoch_miou * cfg.SUSPICIOUS_RATE:\n","            #   ## TO DO: define log file or create a log file##\n","            #     with open(cfg.LOG_SUSPICIOUS_FILES, 'a+') as f:\n","            #         for filename in images_filename:\n","            #             f.write(\"{}\\n\".format(filename))\n","            #         f.flush()\n","\n","            # last_epoch_miou = epoch_miou / iteration\n","            \n","            loss.backward()\n","            loss_plot.append(loss.item())\n","            iou_plot.append(mean_iou.item())\n","            optimizer.step()\n","\n","        torch.save(net.state_dict(), \n","                    pjoin(cfg.WEIGHTS_SAVE_ROOT, \"weights_ep_%d_%.3f_%.3f.pth\" \n","                            % (epoch, epoch_loss / epoch_size, epoch_miou / epoch_size)))\n","    \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gl-yCIdGOCQN","outputId":"9b186c58-bd8e-4a5a-9783-93826efd28f6"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Pick device:  cuda\n","Generating net:  unet_resnet101\n","Preparing data... batch_size: 4, image_size: (768, 256), crop_offset: 690\n","Let us train ...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/1874 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-1] LR: 0.0010: iter loss: 1.119, iter iou: 0.402, epoch loss: 1.119, epoch iou: 0.402,  time cost: 8.679 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 1/1874 [00:10<5:36:13, 10.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-2] LR: 0.0010: iter loss: 1.169, iter iou: 0.353, epoch loss: 1.144, epoch iou: 0.378,  time cost: 9.140 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 2/1874 [00:19<5:03:34,  9.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-3] LR: 0.0010: iter loss: 1.006, iter iou: 0.460, epoch loss: 1.098, epoch iou: 0.405,  time cost: 9.001 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 3/1874 [00:28<4:53:07,  9.40s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-4] LR: 0.0010: iter loss: 0.970, iter iou: 0.478, epoch loss: 1.066, epoch iou: 0.423,  time cost: 16.074 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 4/1874 [00:44<6:15:03, 12.03s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-5] LR: 0.0010: iter loss: 0.902, iter iou: 0.499, epoch loss: 1.033, epoch iou: 0.438,  time cost: 11.890 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 5/1874 [00:56<6:13:13, 11.98s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-6] LR: 0.0010: iter loss: 0.823, iter iou: 0.623, epoch loss: 0.998, epoch iou: 0.469,  time cost: 11.518 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 6/1874 [01:08<6:08:11, 11.83s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-7] LR: 0.0010: iter loss: 0.808, iter iou: 0.536, epoch loss: 0.971, epoch iou: 0.479,  time cost: 10.701 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 7/1874 [01:18<5:56:34, 11.46s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-8] LR: 0.0010: iter loss: 0.787, iter iou: 0.529, epoch loss: 0.948, epoch iou: 0.485,  time cost: 10.317 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 8/1874 [01:29<5:45:04, 11.10s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-9] LR: 0.0010: iter loss: 0.723, iter iou: 0.591, epoch loss: 0.923, epoch iou: 0.497,  time cost: 12.981 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 9/1874 [01:42<6:03:15, 11.69s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-10] LR: 0.0010: iter loss: 0.722, iter iou: 0.496, epoch loss: 0.903, epoch iou: 0.497,  time cost: 13.317 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 10/1874 [01:55<6:18:46, 12.19s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-11] LR: 0.0010: iter loss: 0.669, iter iou: 0.620, epoch loss: 0.882, epoch iou: 0.508,  time cost: 11.333 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 11/1874 [02:06<6:10:22, 11.93s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-12] LR: 0.0010: iter loss: 0.646, iter iou: 0.653, epoch loss: 0.862, epoch iou: 0.520,  time cost: 9.384 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 12/1874 [02:16<5:46:09, 11.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-13] LR: 0.0010: iter loss: 0.632, iter iou: 0.650, epoch loss: 0.844, epoch iou: 0.530,  time cost: 11.089 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 13/1874 [02:27<5:45:20, 11.13s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-14] LR: 0.0010: iter loss: 0.597, iter iou: 0.621, epoch loss: 0.827, epoch iou: 0.537,  time cost: 10.533 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 14/1874 [02:37<5:39:30, 10.95s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-15] LR: 0.0010: iter loss: 0.620, iter iou: 0.553, epoch loss: 0.813, epoch iou: 0.538,  time cost: 12.143 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 15/1874 [02:50<5:50:31, 11.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-16] LR: 0.0010: iter loss: 0.594, iter iou: 0.608, epoch loss: 0.799, epoch iou: 0.542,  time cost: 10.393 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 16/1874 [03:00<5:41:43, 11.04s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-17] LR: 0.0010: iter loss: 0.561, iter iou: 0.657, epoch loss: 0.785, epoch iou: 0.549,  time cost: 11.494 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 17/1874 [03:11<5:45:45, 11.17s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-18] LR: 0.0010: iter loss: 0.562, iter iou: 0.676, epoch loss: 0.773, epoch iou: 0.556,  time cost: 13.053 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 18/1874 [03:25<6:03:07, 11.74s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-19] LR: 0.0010: iter loss: 0.618, iter iou: 0.530, epoch loss: 0.765, epoch iou: 0.554,  time cost: 11.032 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 19/1874 [03:36<5:56:22, 11.53s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-20] LR: 0.0010: iter loss: 0.527, iter iou: 0.678, epoch loss: 0.753, epoch iou: 0.561,  time cost: 10.273 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 20/1874 [03:46<5:44:28, 11.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-21] LR: 0.0010: iter loss: 0.581, iter iou: 0.542, epoch loss: 0.745, epoch iou: 0.560,  time cost: 9.168 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 21/1874 [03:55<5:26:02, 10.56s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-22] LR: 0.0010: iter loss: 0.561, iter iou: 0.563, epoch loss: 0.736, epoch iou: 0.560,  time cost: 11.336 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 22/1874 [04:06<5:33:04, 10.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-23] LR: 0.0010: iter loss: 0.513, iter iou: 0.634, epoch loss: 0.726, epoch iou: 0.563,  time cost: 10.871 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|          | 23/1874 [04:17<5:33:41, 10.82s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-24] LR: 0.0010: iter loss: 0.517, iter iou: 0.582, epoch loss: 0.718, epoch iou: 0.564,  time cost: 11.501 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 24/1874 [04:29<5:39:47, 11.02s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-25] LR: 0.0010: iter loss: 0.503, iter iou: 0.559, epoch loss: 0.709, epoch iou: 0.564,  time cost: 11.348 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 25/1874 [04:40<5:42:37, 11.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-26] LR: 0.0010: iter loss: 0.508, iter iou: 0.542, epoch loss: 0.701, epoch iou: 0.563,  time cost: 9.948 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 26/1874 [04:50<5:31:36, 10.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-27] LR: 0.0010: iter loss: 0.507, iter iou: 0.631, epoch loss: 0.694, epoch iou: 0.565,  time cost: 10.828 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 27/1874 [05:01<5:32:03, 10.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-28] LR: 0.0010: iter loss: 0.472, iter iou: 0.709, epoch loss: 0.686, epoch iou: 0.570,  time cost: 9.735 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 28/1874 [05:11<5:22:10, 10.47s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-29] LR: 0.0010: iter loss: 0.466, iter iou: 0.632, epoch loss: 0.679, epoch iou: 0.573,  time cost: 9.566 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 29/1874 [05:20<5:13:39, 10.20s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-30] LR: 0.0010: iter loss: 0.470, iter iou: 0.619, epoch loss: 0.672, epoch iou: 0.574,  time cost: 10.514 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 30/1874 [05:31<5:16:18, 10.29s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-31] LR: 0.0010: iter loss: 0.453, iter iou: 0.716, epoch loss: 0.665, epoch iou: 0.579,  time cost: 9.744 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 31/1874 [05:40<5:11:04, 10.13s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-32] LR: 0.0010: iter loss: 0.464, iter iou: 0.658, epoch loss: 0.658, epoch iou: 0.581,  time cost: 11.000 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 32/1874 [05:51<5:18:57, 10.39s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-33] LR: 0.0010: iter loss: 0.482, iter iou: 0.570, epoch loss: 0.653, epoch iou: 0.581,  time cost: 12.034 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 33/1874 [06:03<5:33:54, 10.88s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-34] LR: 0.0010: iter loss: 0.461, iter iou: 0.658, epoch loss: 0.647, epoch iou: 0.583,  time cost: 12.580 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 34/1874 [06:16<5:49:24, 11.39s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-35] LR: 0.0010: iter loss: 0.432, iter iou: 0.655, epoch loss: 0.641, epoch iou: 0.585,  time cost: 10.151 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 35/1874 [06:26<5:37:41, 11.02s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-36] LR: 0.0010: iter loss: 0.460, iter iou: 0.612, epoch loss: 0.636, epoch iou: 0.586,  time cost: 10.266 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 36/1874 [06:36<5:30:39, 10.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-37] LR: 0.0010: iter loss: 0.441, iter iou: 0.647, epoch loss: 0.631, epoch iou: 0.588,  time cost: 10.308 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 37/1874 [06:47<5:26:08, 10.65s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-38] LR: 0.0010: iter loss: 0.427, iter iou: 0.703, epoch loss: 0.626, epoch iou: 0.591,  time cost: 9.048 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 38/1874 [06:56<5:11:06, 10.17s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-39] LR: 0.0010: iter loss: 0.431, iter iou: 0.645, epoch loss: 0.621, epoch iou: 0.592,  time cost: 8.950 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 39/1874 [07:05<4:59:51,  9.80s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-40] LR: 0.0010: iter loss: 0.420, iter iou: 0.685, epoch loss: 0.616, epoch iou: 0.594,  time cost: 7.618 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 40/1874 [07:12<4:39:35,  9.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-41] LR: 0.0010: iter loss: 0.417, iter iou: 0.672, epoch loss: 0.611, epoch iou: 0.596,  time cost: 10.607 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 41/1874 [07:23<4:52:47,  9.58s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-42] LR: 0.0010: iter loss: 0.395, iter iou: 0.746, epoch loss: 0.606, epoch iou: 0.600,  time cost: 10.381 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 42/1874 [07:33<4:59:54,  9.82s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-43] LR: 0.0010: iter loss: 0.392, iter iou: 0.731, epoch loss: 0.601, epoch iou: 0.603,  time cost: 12.842 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 43/1874 [07:46<5:27:31, 10.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-44] LR: 0.0010: iter loss: 0.394, iter iou: 0.684, epoch loss: 0.596, epoch iou: 0.605,  time cost: 9.892 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 44/1874 [07:56<5:19:35, 10.48s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-45] LR: 0.0010: iter loss: 0.420, iter iou: 0.637, epoch loss: 0.592, epoch iou: 0.605,  time cost: 10.424 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 45/1874 [08:06<5:18:52, 10.46s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-46] LR: 0.0010: iter loss: 0.423, iter iou: 0.672, epoch loss: 0.588, epoch iou: 0.607,  time cost: 9.987 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 46/1874 [08:16<5:14:28, 10.32s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-47] LR: 0.0010: iter loss: 0.403, iter iou: 0.672, epoch loss: 0.584, epoch iou: 0.608,  time cost: 9.604 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 47/1874 [08:26<5:07:43, 10.11s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-48] LR: 0.0010: iter loss: 0.399, iter iou: 0.687, epoch loss: 0.581, epoch iou: 0.610,  time cost: 10.685 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 48/1874 [08:37<5:12:46, 10.28s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-49] LR: 0.0010: iter loss: 0.386, iter iou: 0.690, epoch loss: 0.577, epoch iou: 0.612,  time cost: 9.167 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 49/1874 [08:46<5:02:32,  9.95s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-50] LR: 0.0010: iter loss: 0.422, iter iou: 0.676, epoch loss: 0.573, epoch iou: 0.613,  time cost: 11.875 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 50/1874 [08:58<5:19:51, 10.52s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-51] LR: 0.0010: iter loss: 0.393, iter iou: 0.698, epoch loss: 0.570, epoch iou: 0.614,  time cost: 10.083 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 51/1874 [09:08<5:15:43, 10.39s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-52] LR: 0.0010: iter loss: 0.391, iter iou: 0.648, epoch loss: 0.567, epoch iou: 0.615,  time cost: 11.438 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 52/1874 [09:19<5:25:06, 10.71s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-53] LR: 0.0010: iter loss: 0.390, iter iou: 0.674, epoch loss: 0.563, epoch iou: 0.616,  time cost: 9.802 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 53/1874 [09:29<5:16:41, 10.43s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-54] LR: 0.0010: iter loss: 0.372, iter iou: 0.733, epoch loss: 0.560, epoch iou: 0.618,  time cost: 9.508 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 54/1874 [09:39<5:08:09, 10.16s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-55] LR: 0.0010: iter loss: 0.378, iter iou: 0.706, epoch loss: 0.556, epoch iou: 0.620,  time cost: 12.267 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 55/1874 [09:51<5:27:05, 10.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-56] LR: 0.0010: iter loss: 0.401, iter iou: 0.666, epoch loss: 0.554, epoch iou: 0.621,  time cost: 9.459 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 56/1874 [10:00<5:14:50, 10.39s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-57] LR: 0.0010: iter loss: 0.367, iter iou: 0.720, epoch loss: 0.550, epoch iou: 0.623,  time cost: 10.123 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 57/1874 [10:10<5:12:14, 10.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-58] LR: 0.0010: iter loss: 0.354, iter iou: 0.775, epoch loss: 0.547, epoch iou: 0.625,  time cost: 9.561 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 58/1874 [10:20<5:05:14, 10.09s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-59] LR: 0.0010: iter loss: 0.361, iter iou: 0.712, epoch loss: 0.544, epoch iou: 0.627,  time cost: 9.063 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 59/1874 [10:29<4:55:50,  9.78s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-60] LR: 0.0010: iter loss: 0.378, iter iou: 0.700, epoch loss: 0.541, epoch iou: 0.628,  time cost: 7.601 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 60/1874 [10:37<4:35:52,  9.13s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-61] LR: 0.0010: iter loss: 0.375, iter iou: 0.662, epoch loss: 0.538, epoch iou: 0.628,  time cost: 8.934 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 61/1874 [10:46<4:34:01,  9.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-62] LR: 0.0010: iter loss: 0.414, iter iou: 0.615, epoch loss: 0.536, epoch iou: 0.628,  time cost: 9.087 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 62/1874 [10:55<4:34:02,  9.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-63] LR: 0.0010: iter loss: 0.379, iter iou: 0.676, epoch loss: 0.534, epoch iou: 0.629,  time cost: 11.644 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 63/1874 [11:06<4:57:05,  9.84s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-64] LR: 0.0010: iter loss: 0.373, iter iou: 0.688, epoch loss: 0.531, epoch iou: 0.630,  time cost: 12.493 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 64/1874 [11:19<5:20:56, 10.64s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-65] LR: 0.0010: iter loss: 0.386, iter iou: 0.643, epoch loss: 0.529, epoch iou: 0.630,  time cost: 10.394 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 65/1874 [11:29<5:18:34, 10.57s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-66] LR: 0.0010: iter loss: 0.355, iter iou: 0.650, epoch loss: 0.526, epoch iou: 0.630,  time cost: 11.109 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 66/1874 [11:40<5:23:19, 10.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-67] LR: 0.0010: iter loss: 0.362, iter iou: 0.649, epoch loss: 0.524, epoch iou: 0.631,  time cost: 9.368 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 67/1874 [11:50<5:10:48, 10.32s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-68] LR: 0.0010: iter loss: 0.362, iter iou: 0.753, epoch loss: 0.522, epoch iou: 0.632,  time cost: 9.131 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 68/1874 [11:59<4:59:52,  9.96s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-69] LR: 0.0010: iter loss: 0.360, iter iou: 0.702, epoch loss: 0.519, epoch iou: 0.633,  time cost: 11.294 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 69/1874 [12:10<5:11:43, 10.36s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-70] LR: 0.0010: iter loss: 0.357, iter iou: 0.680, epoch loss: 0.517, epoch iou: 0.634,  time cost: 9.371 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 70/1874 [12:20<5:02:42, 10.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-71] LR: 0.0010: iter loss: 0.385, iter iou: 0.636, epoch loss: 0.515, epoch iou: 0.634,  time cost: 10.427 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 71/1874 [12:30<5:05:44, 10.17s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-72] LR: 0.0010: iter loss: 0.370, iter iou: 0.655, epoch loss: 0.513, epoch iou: 0.634,  time cost: 10.696 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 72/1874 [12:41<5:10:14, 10.33s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-73] LR: 0.0010: iter loss: 0.333, iter iou: 0.716, epoch loss: 0.511, epoch iou: 0.636,  time cost: 12.752 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 73/1874 [12:53<5:31:51, 11.06s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-74] LR: 0.0010: iter loss: 0.406, iter iou: 0.627, epoch loss: 0.509, epoch iou: 0.635,  time cost: 11.292 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 74/1874 [13:05<5:33:50, 11.13s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-75] LR: 0.0010: iter loss: 0.357, iter iou: 0.740, epoch loss: 0.507, epoch iou: 0.637,  time cost: 10.273 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 75/1874 [13:15<5:25:59, 10.87s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-76] LR: 0.0010: iter loss: 0.345, iter iou: 0.755, epoch loss: 0.505, epoch iou: 0.638,  time cost: 10.561 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 76/1874 [13:26<5:22:56, 10.78s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-77] LR: 0.0010: iter loss: 0.341, iter iou: 0.752, epoch loss: 0.503, epoch iou: 0.640,  time cost: 10.749 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 77/1874 [13:36<5:22:30, 10.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-78] LR: 0.0010: iter loss: 0.379, iter iou: 0.667, epoch loss: 0.501, epoch iou: 0.640,  time cost: 11.119 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 78/1874 [13:47<5:25:32, 10.88s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-79] LR: 0.0010: iter loss: 0.338, iter iou: 0.763, epoch loss: 0.499, epoch iou: 0.642,  time cost: 9.936 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 79/1874 [13:57<5:16:52, 10.59s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-80] LR: 0.0010: iter loss: 0.338, iter iou: 0.762, epoch loss: 0.497, epoch iou: 0.643,  time cost: 9.146 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 80/1874 [14:07<5:03:50, 10.16s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-81] LR: 0.0010: iter loss: 0.323, iter iou: 0.765, epoch loss: 0.495, epoch iou: 0.645,  time cost: 9.452 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 81/1874 [14:16<4:57:10,  9.94s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-82] LR: 0.0010: iter loss: 0.371, iter iou: 0.629, epoch loss: 0.493, epoch iou: 0.645,  time cost: 10.178 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 82/1874 [14:26<4:59:13, 10.02s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-83] LR: 0.0010: iter loss: 0.342, iter iou: 0.762, epoch loss: 0.492, epoch iou: 0.646,  time cost: 7.677 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 83/1874 [14:34<4:38:01,  9.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-84] LR: 0.0010: iter loss: 0.330, iter iou: 0.716, epoch loss: 0.490, epoch iou: 0.647,  time cost: 8.674 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 84/1874 [14:42<4:32:10,  9.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-85] LR: 0.0010: iter loss: 0.333, iter iou: 0.766, epoch loss: 0.488, epoch iou: 0.648,  time cost: 10.419 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 85/1874 [14:53<4:43:41,  9.51s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-86] LR: 0.0010: iter loss: 0.359, iter iou: 0.694, epoch loss: 0.486, epoch iou: 0.649,  time cost: 10.339 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 86/1874 [15:03<4:50:52,  9.76s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-87] LR: 0.0010: iter loss: 0.375, iter iou: 0.649, epoch loss: 0.485, epoch iou: 0.649,  time cost: 10.707 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 87/1874 [15:14<4:59:08, 10.04s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-88] LR: 0.0010: iter loss: 0.348, iter iou: 0.716, epoch loss: 0.484, epoch iou: 0.650,  time cost: 9.129 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 88/1874 [15:23<4:50:45,  9.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-89] LR: 0.0010: iter loss: 0.324, iter iou: 0.767, epoch loss: 0.482, epoch iou: 0.651,  time cost: 10.344 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 89/1874 [15:33<4:55:46,  9.94s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-90] LR: 0.0010: iter loss: 0.327, iter iou: 0.712, epoch loss: 0.480, epoch iou: 0.652,  time cost: 10.054 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 90/1874 [15:43<4:56:36,  9.98s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-91] LR: 0.0010: iter loss: 0.329, iter iou: 0.756, epoch loss: 0.478, epoch iou: 0.653,  time cost: 10.143 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 91/1874 [15:54<4:57:56, 10.03s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-92] LR: 0.0010: iter loss: 0.344, iter iou: 0.710, epoch loss: 0.477, epoch iou: 0.653,  time cost: 9.154 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 92/1874 [16:03<4:50:01,  9.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-93] LR: 0.0010: iter loss: 0.308, iter iou: 0.751, epoch loss: 0.475, epoch iou: 0.654,  time cost: 8.702 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 93/1874 [16:11<4:40:19,  9.44s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-94] LR: 0.0010: iter loss: 0.344, iter iou: 0.671, epoch loss: 0.474, epoch iou: 0.655,  time cost: 8.738 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 94/1874 [16:20<4:33:53,  9.23s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-95] LR: 0.0010: iter loss: 0.359, iter iou: 0.673, epoch loss: 0.473, epoch iou: 0.655,  time cost: 9.299 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 95/1874 [16:30<4:34:20,  9.25s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-96] LR: 0.0010: iter loss: 0.307, iter iou: 0.763, epoch loss: 0.471, epoch iou: 0.656,  time cost: 10.829 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 96/1874 [16:40<4:48:10,  9.72s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-97] LR: 0.0010: iter loss: 0.333, iter iou: 0.725, epoch loss: 0.469, epoch iou: 0.657,  time cost: 9.730 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 97/1874 [16:50<4:48:05,  9.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-98] LR: 0.0010: iter loss: 0.312, iter iou: 0.752, epoch loss: 0.468, epoch iou: 0.658,  time cost: 9.633 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 98/1874 [17:00<4:47:07,  9.70s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-99] LR: 0.0010: iter loss: 0.369, iter iou: 0.669, epoch loss: 0.467, epoch iou: 0.658,  time cost: 9.615 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 99/1874 [17:09<4:46:10,  9.67s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-100] LR: 0.0010: iter loss: 0.330, iter iou: 0.733, epoch loss: 0.465, epoch iou: 0.658,  time cost: 9.958 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 100/1874 [17:19<4:48:29,  9.76s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-101] LR: 0.0010: iter loss: 0.313, iter iou: 0.752, epoch loss: 0.464, epoch iou: 0.659,  time cost: 9.652 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 101/1874 [17:29<4:47:26,  9.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-102] LR: 0.0010: iter loss: 0.309, iter iou: 0.721, epoch loss: 0.462, epoch iou: 0.660,  time cost: 10.129 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 102/1874 [17:39<4:50:45,  9.85s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-103] LR: 0.0010: iter loss: 0.370, iter iou: 0.657, epoch loss: 0.461, epoch iou: 0.660,  time cost: 9.483 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 103/1874 [17:49<4:47:32,  9.74s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-104] LR: 0.0010: iter loss: 0.300, iter iou: 0.745, epoch loss: 0.460, epoch iou: 0.661,  time cost: 9.577 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 104/1874 [17:58<4:45:53,  9.69s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-105] LR: 0.0010: iter loss: 0.292, iter iou: 0.761, epoch loss: 0.458, epoch iou: 0.662,  time cost: 8.940 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 105/1874 [18:07<4:39:06,  9.47s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-106] LR: 0.0010: iter loss: 0.329, iter iou: 0.708, epoch loss: 0.457, epoch iou: 0.662,  time cost: 9.045 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 106/1874 [18:16<4:35:09,  9.34s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-107] LR: 0.0010: iter loss: 0.318, iter iou: 0.741, epoch loss: 0.456, epoch iou: 0.663,  time cost: 9.650 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 107/1874 [18:26<4:37:48,  9.43s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-108] LR: 0.0010: iter loss: 0.270, iter iou: 0.807, epoch loss: 0.454, epoch iou: 0.664,  time cost: 9.315 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 108/1874 [18:35<4:36:35,  9.40s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-109] LR: 0.0010: iter loss: 0.340, iter iou: 0.684, epoch loss: 0.453, epoch iou: 0.664,  time cost: 10.935 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 109/1874 [18:46<4:49:56,  9.86s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-110] LR: 0.0010: iter loss: 0.343, iter iou: 0.707, epoch loss: 0.452, epoch iou: 0.665,  time cost: 10.688 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 110/1874 [18:57<4:57:08, 10.11s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-111] LR: 0.0010: iter loss: 0.347, iter iou: 0.692, epoch loss: 0.451, epoch iou: 0.665,  time cost: 11.605 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 111/1874 [19:08<5:10:12, 10.56s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-112] LR: 0.0010: iter loss: 0.281, iter iou: 0.770, epoch loss: 0.450, epoch iou: 0.666,  time cost: 9.909 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 112/1874 [19:18<5:04:17, 10.36s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-113] LR: 0.0010: iter loss: 0.378, iter iou: 0.662, epoch loss: 0.449, epoch iou: 0.666,  time cost: 9.552 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 113/1874 [19:28<4:57:00, 10.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-114] LR: 0.0010: iter loss: 0.353, iter iou: 0.689, epoch loss: 0.448, epoch iou: 0.666,  time cost: 10.551 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 114/1874 [19:38<5:00:36, 10.25s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-115] LR: 0.0010: iter loss: 0.301, iter iou: 0.747, epoch loss: 0.447, epoch iou: 0.667,  time cost: 11.470 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 115/1874 [19:50<5:11:09, 10.61s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-116] LR: 0.0010: iter loss: 0.296, iter iou: 0.750, epoch loss: 0.446, epoch iou: 0.668,  time cost: 11.564 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 116/1874 [20:01<5:19:22, 10.90s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-117] LR: 0.0010: iter loss: 0.356, iter iou: 0.714, epoch loss: 0.445, epoch iou: 0.668,  time cost: 9.798 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 117/1874 [20:11<5:09:32, 10.57s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-118] LR: 0.0010: iter loss: 0.346, iter iou: 0.704, epoch loss: 0.444, epoch iou: 0.668,  time cost: 9.724 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 118/1874 [20:21<5:01:57, 10.32s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-119] LR: 0.0010: iter loss: 0.309, iter iou: 0.754, epoch loss: 0.443, epoch iou: 0.669,  time cost: 9.865 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 119/1874 [20:31<4:57:46, 10.18s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-120] LR: 0.0010: iter loss: 0.304, iter iou: 0.766, epoch loss: 0.442, epoch iou: 0.670,  time cost: 10.840 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 120/1874 [20:42<5:03:23, 10.38s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-121] LR: 0.0010: iter loss: 0.298, iter iou: 0.761, epoch loss: 0.440, epoch iou: 0.671,  time cost: 10.506 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 121/1874 [20:52<5:04:22, 10.42s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-122] LR: 0.0010: iter loss: 0.365, iter iou: 0.675, epoch loss: 0.440, epoch iou: 0.671,  time cost: 12.030 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 122/1874 [21:04<5:18:16, 10.90s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-123] LR: 0.0010: iter loss: 0.308, iter iou: 0.741, epoch loss: 0.439, epoch iou: 0.671,  time cost: 11.935 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 123/1874 [21:16<5:27:08, 11.21s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-124] LR: 0.0010: iter loss: 0.356, iter iou: 0.706, epoch loss: 0.438, epoch iou: 0.671,  time cost: 9.791 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 124/1874 [21:26<5:14:37, 10.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-125] LR: 0.0010: iter loss: 0.265, iter iou: 0.794, epoch loss: 0.437, epoch iou: 0.672,  time cost: 9.103 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 125/1874 [21:35<4:59:39, 10.28s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-126] LR: 0.0010: iter loss: 0.302, iter iou: 0.750, epoch loss: 0.436, epoch iou: 0.673,  time cost: 10.414 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 126/1874 [21:45<5:00:39, 10.32s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-127] LR: 0.0010: iter loss: 0.279, iter iou: 0.786, epoch loss: 0.434, epoch iou: 0.674,  time cost: 10.243 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 127/1874 [21:56<4:59:50, 10.30s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-128] LR: 0.0010: iter loss: 0.323, iter iou: 0.737, epoch loss: 0.434, epoch iou: 0.674,  time cost: 11.473 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 128/1874 [22:07<5:09:51, 10.65s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-129] LR: 0.0010: iter loss: 0.342, iter iou: 0.706, epoch loss: 0.433, epoch iou: 0.675,  time cost: 9.402 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 129/1874 [22:16<4:58:50, 10.28s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-130] LR: 0.0010: iter loss: 0.346, iter iou: 0.706, epoch loss: 0.432, epoch iou: 0.675,  time cost: 10.827 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 130/1874 [22:27<5:03:26, 10.44s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-131] LR: 0.0010: iter loss: 0.322, iter iou: 0.741, epoch loss: 0.431, epoch iou: 0.675,  time cost: 10.060 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 131/1874 [22:37<4:59:58, 10.33s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-132] LR: 0.0010: iter loss: 0.372, iter iou: 0.673, epoch loss: 0.431, epoch iou: 0.675,  time cost: 8.837 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 132/1874 [22:46<4:46:48,  9.88s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-133] LR: 0.0010: iter loss: 0.310, iter iou: 0.735, epoch loss: 0.430, epoch iou: 0.676,  time cost: 9.700 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 133/1874 [22:56<4:45:08,  9.83s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-134] LR: 0.0010: iter loss: 0.237, iter iou: 0.809, epoch loss: 0.429, epoch iou: 0.677,  time cost: 9.918 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 134/1874 [23:06<4:45:44,  9.85s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n","[Epoch-0 Iter-135] LR: 0.0010: iter loss: 0.347, iter iou: 0.693, epoch loss: 0.428, epoch iou: 0.677,  time cost: 9.500 s\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 135/1874 [23:15<4:42:37,  9.75s/it]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([786432, 2])\n","torch.Size([786432])\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"37lGdu_HuBEs"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 5))\n","plt.suptitle('dice loss + cross-entropy training')\n","plt.subplot(1, 2, 1)\n","plt.plot(loss_plot)\n","plt.ylabel('loss')\n","plt.xlabel('iteration')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(iou_plot)\n","plt.ylabel('Image-IoU (%)')\n","plt.xlabel('iteration')"],"metadata":{"id":"qE_1dpNRcsVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(net.state_dict(), \"result.pt\")"],"metadata":{"id":"4SzUTrZYZzMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(net.state_dict(), \n","                    pjoin(cfg.WEIGHTS_SAVE_ROOT, \"weights_ep_%d_%.3f_%.3f.pth\" \n","                            % (epoch, epoch_loss / epoch_size, epoch_miou / epoch_size)))"],"metadata":{"id":"OQmsLOcbaiXL"},"execution_count":null,"outputs":[]}]}