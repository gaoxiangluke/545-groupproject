{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline_deeplab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":19,"metadata":{"id":"hV3OfnRxglel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650056856506,"user_tz":240,"elapsed":1309,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}},"outputId":"7cee790d-56ef-4d51-9dfb-6e9fe98a0f2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/Shareddrives/EECS 545 Project/5DE/lane-detection-2019-howard')"],"metadata":{"id":"sM6qOXiJK2hf","executionInfo":{"status":"ok","timestamp":1650056856507,"user_tz":240,"elapsed":66,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","class UNetFactory(nn.Module):\n","    \"\"\"\n","    本质上就是一个U型的网络，先encode，后decode，中间可能有架bridge。\n","    其中encoder需要输出skip到decode那边做concatenate，使得decode阶段能补充信息。\n","    bridge不能存在下采样和上采样的操作。\n","    \"\"\"\n","    def __init__(self, encoder_blocks, decoder_blocks, bridge=None):\n","        super(UNetFactory, self).__init__()\n","        self.encoder = UNetEncoder(encoder_blocks)\n","        self.bridge = bridge\n","        self.decoder = UNetDecoder(decoder_blocks)\n","\n","    def forward(self, x):\n","        res = self.encoder(x)\n","        out, skips = res[0], res[1:]\n","        if self.bridge is not None:\n","            out = self.bridge(out)\n","        out = self.decoder(out, skips)\n","        return out\n","\n","class UNetEncoder(nn.Module):\n","    \"\"\"\n","    encoder会有多次下采样，下采样前的feature map要作为skip缓存起来将来送到decoder用。\n","    这里约定，以下采样为界线，将encoder分成多个block，其中第一个block无下采样操作，后面的每个block内都\n","    含有一次下采样操作。\n","    \"\"\"\n","    def __init__(self, blocks):\n","        super(UNetEncoder, self).__init__()\n","        assert len(blocks) > 0\n","        self.blocks = nn.ModuleList(blocks)\n","\n","    def forward(self, x):\n","        skips = []\n","        for i in range(len(self.blocks) - 1):\n","            x = self.blocks[i](x)\n","            skips.append(x)\n","        res = [self.blocks[i+1](x)]\n","        res += skips\n","        return res # 只能以这种方式返回多个tensor\n","\n","class UNetDecoder(nn.Module):\n","    \"\"\"\n","    decoder会有多次上采样，每次上采样后，要跟相应的skip做concatenate。\n","    这里约定，以上采样为界线，将decoder分成多个block，其中最后一个block无上采样操作，其他block内\n","    都含有一次上采样。如此一来，除第一个block以外，其他block都先做concatenate。\n","    \"\"\"\n","    def __init__(self, blocks):\n","        super(UNetDecoder, self).__init__()\n","        assert len(blocks) > 1\n","        self.blocks = nn.ModuleList(blocks)\n","    \n","    def _center_crop(self, skip, x):\n","        \"\"\"\n","        skip和x，谁比较大，就裁剪谁\n","        \"\"\"\n","        _, _, h1, w1 = skip.shape\n","        _, _, h2, w2 = x.shape\n","        ht, wt = min(h1, h2), min(w1, w2)\n","        dh1 = (h1 - ht) // 2 if h1 > ht else 0\n","        dw1 = (w1 - wt) // 2 if w1 > wt else 0\n","        dh2 = (h2 - ht) // 2 if h2 > ht else 0\n","        dw2 = (w2 - wt) // 2 if w2 > wt else 0\n","        return skip[:, :, dh1: (dh1 + ht), dw1: (dw1 + wt)], \\\n","                x[:, :, dh2: (dh2 + ht), dw2: (dw2 + wt)]\n","\n","    def forward(self, x, skips, reverse_skips=True):\n","        assert len(skips) == len(self.blocks) - 1\n","        if reverse_skips:\n","            skips = skips[::-1]\n","        x = self.blocks[0](x)\n","        for i in range(1, len(self.blocks)):\n","            skip, x = self._center_crop(skips[i-1], x)\n","            x = torch.cat([skip, x], dim=1)\n","            x = self.blocks[i](x)\n","        return x\n","\n","def unet_convs(in_channels, out_channels, padding=0):\n","    \"\"\"\n","    unet论文里出现次数最多的2个conv3x3(non-padding)的结构\n","    \"\"\"\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding, bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","\n","def unet(in_channels, out_channels):\n","    \"\"\"\n","    构造跟论文一致的unet网络\n","    https://arxiv.org/abs/1505.04597\n","    \"\"\"\n","    # encoder\n","    encoder_blocks = [\n","        # two conv3x3\n","        unet_convs(in_channels, 64),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(64, 128)\n","        ),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(128, 256)\n","        ),\n","        # max pool 2x2, two conv3x3\n","        nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n","            unet_convs(256, 512)\n","        ),\n","        # max pool 2x2\n","        nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n","    ]\n","    # bridge\n","    bridge = nn.Sequential(\n","        # two conv3x3\n","        unet_convs(512, 1024)\n","    )\n","    # decoder\n","    decoder_blocks = [\n","        # up-conv2x2\n","        nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(1024, 512),\n","            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(512, 256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, up-conv2x2\n","        nn.Sequential(\n","            unet_convs(256, 128),\n","            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n","        ),\n","        # two conv3x3, conv1x1\n","        nn.Sequential(\n","            unet_convs(128, 64),\n","            nn.Conv2d(64, out_channels, kernel_size=1)\n","        )\n","    ]\n","    return UNetFactory(encoder_blocks, decoder_blocks, bridge)\n","\n","def unet_resnet(resnet_type, in_channels, out_channels, pretrained=True):\n","    \"\"\"\n","    利用resnet作为encoder，相应地，decoder也做一些改动，使得输出的尺寸跟原始的一致\n","    \"\"\"\n","    if resnet_type == 'resnet18':\n","        resnet = torchvision.models.resnet.resnet18(pretrained)\n","        encoder_out_channels = [in_channels, 64, 64, 128, 256, 512]  # encoder各个block的输出channel\n","    elif resnet_type == 'resnet34':\n","        resnet = torchvision.models.resnet.resnet34(pretrained)\n","        encoder_out_channels = [in_channels, 64, 64, 128, 256, 512]\n","    elif resnet_type == 'resnet50':\n","        resnet = torchvision.models.resnet.resnet50(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnet101':\n","        resnet = torchvision.models.resnet.resnet101(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnet152':\n","        resnet = torchvision.models.resnet.resnet152(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    elif resnet_type == 'resnext50_32x4d':\n","        resnet = torchvision.models.resnet.resnext50_32x4d(pretrained)\n","        encoder_out_channels = [in_channels, 64, 256, 512, 1024, 2048]\n","    else:\n","        raise ValueError(\"unexpected resnet_type\")\n","\n","    # encoder\n","    encoder_blocks = [\n","        # org input\n","        nn.Sequential(),\n","        # conv1\n","        nn.Sequential(\n","            resnet.conv1,\n","            resnet.bn1,\n","            resnet.relu\n","        ),\n","        # conv2_x\n","        nn.Sequential(\n","            resnet.maxpool,\n","            resnet.layer1\n","        ),\n","        # conv3_x\n","        resnet.layer2,\n","        # conv4_x\n","        resnet.layer3,\n","        # conv5_x\n","        resnet.layer4\n","    ]\n","    # bridge\n","    bridge = None  # 感觉并无必要\n","    # decoder\n","    decoder_blocks = []\n","    in_ch = encoder_out_channels[-1]\n","    out_ch = in_ch // 2\n","    decoder_blocks.append(nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)) # up-conv2x2\n","    for i in range(1, len(encoder_blocks)-1):\n","        in_ch = encoder_out_channels[-i-1] + out_ch  # cat\n","        decoder_blocks.append(nn.Sequential(  # two conv3x3, up-conv2x2\n","            unet_convs(in_ch, out_ch, padding=1),\n","            nn.ConvTranspose2d(out_ch, out_ch//2, kernel_size=2, stride=2),\n","        ))\n","        out_ch = out_ch // 2\n","    in_ch = encoder_out_channels[0] + out_ch  # cat\n","    decoder_blocks.append(nn.Sequential(  # two conv3x3, conv1x1\n","        unet_convs(in_ch, out_ch, padding=1),\n","        nn.Conv2d(out_ch, out_channels, kernel_size=1)\n","    ))\n","\n","    return UNetFactory(encoder_blocks, decoder_blocks, bridge)"],"metadata":{"id":"MDTNSK_bQCqL","executionInfo":{"status":"ok","timestamp":1650056856507,"user_tz":240,"elapsed":64,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rUbpIzPCRmNE","executionInfo":{"status":"ok","timestamp":1650056856507,"user_tz":240,"elapsed":62,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","@description: Configure Class \n","\"\"\"\n","\n","from os.path import join as pjoin\n","from os.path import dirname, abspath\n","import torch\n","\n","class ConfigTrain(object):\n","    # 目录\n","    PROJECT_ROOT = \"/content/drive/Shareddrives/EECS 545 Project/5DE/lane-detection-2019-howard\"\n","    DATA_LIST_ROOT = pjoin(PROJECT_ROOT, 'data_list')\n","    TRAIN_ROOT = \"/content/drive/Shareddrives/EECS 545 Project/data\"\n","    IMAGE_ROOT = pjoin(TRAIN_ROOT, 'Image_Data')\n","    LABEL_ROOT = pjoin(TRAIN_ROOT, 'Gray_Label')\n","    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'weights')\n","    WEIGHTS_SAVE_ROOT = pjoin(WEIGHTS_ROOT, '1536x512_b2_unet_resnext50_32x4d')\n","    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\n","\n","    # log文件\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b1.log')\n","    # LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b4.log')\n","    LOG_SUSPICIOUS_FILES = pjoin(LOG_ROOT, 'suspicious_files_b2.log')\n","\n","    # 设备\n","    DEVICE = 'cuda:0' \n","    \n","    if torch.cuda.is_available():\n","      print(\"Using the GPU. You are good to go!\")\n","      DEVICE = 'cuda'\n","    else:\n","      print(\"Using the CPU. Overall speed may be slowed down\")\n","      DEVICE = 'cpu'\n","    \n","    # 网络类型\n","    NET_NAME = 'unet_resnet101'\n","    #NET_NAME = 'resnext50_32x4d'\n","    # 网络参数\n","    NUM_CLASSES = 8  # 8个类别\n","    IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\n","    # IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\n","    #IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\n","    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\n","    # BATCH_SIZE = 8  # 数据批次大小\n","    # BATCH_SIZE = 1  # 数据批次大小\n","    # BATCH_SIZE = 4  # 数据批次大小\n","    BATCH_SIZE = 2  # 数据批次大小\n","    EPOCH_NUM = 1  # 总轮次\n","    PRETRAIN = False # 是否加载预训练的权重\n","    EPOCH_BEGIN = 0  # 接着前面的epoch训练，默认0，表示从头训练\n","    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'result_6.pt')\n","    BASE_LR = 0.001  # 学习率\n","    LR_STRATEGY = [\n","        [0.001], # epoch 0\n","        [0.001], # epoch 1\n","        [0.001], # epoch 2\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 3\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 4\n","        [0.001, 0.0006, 0.0003, 0.0001, 0.0004, 0.0008, 0.001], # epoch 5\n","        [0.0004, 0.0003, 0.0002, 0.0001, 0.0002, 0.0003, 0.0004], # epoch 6\n","        [0.0004, 0.0003, 0.0002, 0.0001, 0.0002, 0.0003, 0.0004], # epoch 7\n","    ]\n","    SUSPICIOUS_RATE = 0.8  # 可疑比例：当某个iteration的miou比当前epoch_miou的可疑比例还要小的时候，记录此次iteration的训练数据索引，人工排查是否数据有问题\n","\n","## TO DO: Define PROJECT_ROOT##\n","'''    \n","class ConfigInference(object):\n","    # 目录\n","    PROJECT_ROOT = dirname(abspath(__file__)) \n","    DATA_ROOT = pjoin(PROJECT_ROOT, 'data')\n","    IMAGE_ROOT = pjoin(DATA_ROOT, 'TestImage')\n","    LABEL_ROOT = pjoin(DATA_ROOT, 'TestLabel')\n","    OVERLAY_ROOT = pjoin(DATA_ROOT, 'TestOverlay')\n","    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'weights')\n","    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'resnext50_32x4d-7cdf4587.pth')\n","    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\n","\n","    # 设备\n","    DEVICE = 'cuda:0'\n","\n","    # 网络类型\n","    NET_NAME = 'resnext50_32x4d'\n","\n","    # 网络参数\n","    NUM_CLASSES = 8  # 8个类别\n","    # IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\n","    IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\n","    # IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\n","    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\n","    BATCH_SIZE = 1  # 数据批次大小\n","\n","    # 原图的大小\n","    IMAGE_SIZE_ORG = (3384, 1710)\n","'''    "],"metadata":{"id":"dha6U_LzGxtJ","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1650056856507,"user_tz":240,"elapsed":61,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}},"outputId":"d97f2fd5-0888-44e9-efcb-00d76766004e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Using the GPU. You are good to go!\n"]},{"output_type":"execute_result","data":{"text/plain":["\"    \\nclass ConfigInference(object):\\n    # 目录\\n    PROJECT_ROOT = dirname(abspath(__file__)) \\n    DATA_ROOT = pjoin(PROJECT_ROOT, 'data')\\n    IMAGE_ROOT = pjoin(DATA_ROOT, 'TestImage')\\n    LABEL_ROOT = pjoin(DATA_ROOT, 'TestLabel')\\n    OVERLAY_ROOT = pjoin(DATA_ROOT, 'TestOverlay')\\n    WEIGHTS_ROOT = pjoin(PROJECT_ROOT, 'weights')\\n    PRETRAINED_WEIGHTS = pjoin(WEIGHTS_ROOT, '1024x384_b4_unet_resnext50_32x4d', 'resnext50_32x4d-7cdf4587.pth')\\n    LOG_ROOT = pjoin(PROJECT_ROOT, 'logs')\\n\\n    # 设备\\n    DEVICE = 'cuda:0'\\n\\n    # 网络类型\\n    NET_NAME = 'resnext50_32x4d'\\n\\n    # 网络参数\\n    NUM_CLASSES = 8  # 8个类别\\n    # IMAGE_SIZE = (768, 256)  # 训练的图片的尺寸(h,w)\\n    IMAGE_SIZE = (1024, 384)  # 训练的图片的尺寸(h,w)\\n    # IMAGE_SIZE = (1536, 512)  # 训练的图片的尺寸(h,w)\\n    HEIGHT_CROP_OFFSET = 690  # 在height方向上将原图裁掉的offset\\n    BATCH_SIZE = 1  # 数据批次大小\\n\\n    # 原图的大小\\n    IMAGE_SIZE_ORG = (3384, 1710)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["'''\n","Define loss\n","'''\n","class MySoftmaxCrossEntropyLoss(nn.Module):\n","\n","    def __init__(self, nbclasses):\n","        super(MySoftmaxCrossEntropyLoss, self).__init__()\n","        self.nbclasses = nbclasses\n","\n","    def forward(self, inputs, target):\n","        if inputs.dim() > 2:\n","            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n","            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n","            inputs = inputs.contiguous().view(-1, self.nbclasses)  # N,H*W,C => N*H*W,C\n","        target = target.view(-1)\n","        return nn.CrossEntropyLoss(reduction=\"mean\")(inputs, target)\n","\n","\n","class FocalLoss(nn.Module):\n","\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.alpha = torch.tensor([alpha, 1 - alpha])\n","        self.size_average = size_average\n","\n","    def forward(self, inputs, target):\n","        if inputs.dim() > 2:\n","            inputs = inputs\n","            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n","            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n","            inputs = inputs.contiguous().view(-1, inputs.size(2))  # N,H*W,C => N*H*W,C\n","        target = target.view(-1, 1)\n","\n","        logpt = F.log_softmax(inputs,dim=1)\n","        logpt = logpt.gather(1, target)\n","        logpt = logpt.view(-1)\n","        pt = logpt.exp()\n","\n","        if self.alpha is not None:\n","            if self.alpha.type() != inputs.data.type():\n","                self.alpha = self.alpha.type_as(inputs.data)\n","            at = self.alpha.gather(0, target.view(-1))\n","            logpt = logpt * at\n","        # mask = mask.view(-1)\n","        loss = -1 * (1 - pt) ** self.gamma * logpt #* mask\n","        if self.size_average:\n","            return loss.mean()\n","        else:\n","            return loss.sum()\n","\n","\n","def make_one_hot(input, num_classes):\n","    \"\"\"Convert class index tensor to one hot encoding tensor.\n","    Args:\n","         input: A tensor of shape [N, 1, *]\n","         num_classes: An int of number of class\n","    Returns:\n","        A tensor of shape [N, num_classes, *]\n","    \"\"\"\n","    shape = np.array(input.shape)\n","    shape[1] = num_classes\n","    shape = tuple(shape)\n","    result = torch.zeros(shape)\n","    result = result.scatter_(1, input.cpu(), 1)\n","\n","    return result\n","\n","\n","class BinaryDiceLoss(nn.Module):\n","    \"\"\"Dice loss of binary class\n","    Args:\n","        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n","        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n","        predict: A tensor of shape [N, *]\n","        target: A tensor of shape same with predict\n","        reduction: Reduction method to apply, return mean over batch if 'mean',\n","            return sum if 'sum', return a tensor of shape [N,] if 'none'\n","    Returns:\n","        Loss tensor according to arg reduction\n","    Raise:\n","        Exception if unexpected reduction\n","    \"\"\"\n","    def __init__(self, smooth=1, p=2, reduction='mean'):\n","        super(BinaryDiceLoss, self).__init__()\n","        self.smooth = smooth\n","        self.p = p\n","        self.reduction = reduction\n","\n","    def forward(self, predict, target):\n","        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n","        predict = predict.contiguous().view(predict.shape[0], -1)\n","        target = target.contiguous().view(target.shape[0], -1)\n","        num = 2*torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n","        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n","\n","        loss = 1 - num / den\n","\n","        if self.reduction == 'mean':\n","            return loss.mean()\n","        elif self.reduction == 'sum':\n","            return loss.sum()\n","        elif self.reduction == 'none':\n","            return loss\n","        else:\n","            raise Exception('Unexpected reduction {}'.format(self.reduction))\n","\n","\n","class DiceLoss(nn.Module):\n","    \"\"\"Dice loss, need one hot encode input\n","    Args:\n","        weight: An array of shape [num_classes,]\n","        ignore_index: class index to ignore\n","        predict: A tensor of shape [N, C, *]\n","        target: A tensor of same shape with predict\n","        other args pass to BinaryDiceLoss\n","    Return:\n","        same as BinaryDiceLoss\n","    \"\"\"\n","    def __init__(self, weight=None, ignore_index=None, **kwargs):\n","        super(DiceLoss, self).__init__()\n","        self.kwargs = kwargs\n","        self.weight = weight\n","        self.ignore_index = ignore_index\n","\n","    def forward(self, predict, target):\n","        assert predict.shape == target.shape, 'predict & target shape do not match'\n","        dice = BinaryDiceLoss(**self.kwargs)\n","        total_loss = 0\n","        predict = F.softmax(predict, dim=1)\n","\n","        for i in range(target.shape[1]):\n","            if i != self.ignore_index:\n","                dice_loss = dice(predict[:, i], target[:, i])\n","                if self.weight is not None:\n","                    assert self.weight.shape[0] == target.shape[1], \\\n","                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n","                    dice_loss *= self.weights[i]\n","                total_loss += dice_loss\n","\n","        return total_loss/target.shape[1]\n","\n"],"metadata":{"id":"VhCWX0QNWYYI","executionInfo":{"status":"ok","timestamp":1650056856508,"user_tz":240,"elapsed":5,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","\"\"\"\n","Lovasz-Softmax and Jaccard hinge loss in PyTorch\n","Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n","\"\"\"\n","\n","from __future__ import print_function, division\n","\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","try:\n","    from itertools import  ifilterfalse\n","except ImportError: # py3k\n","    from itertools import  filterfalse as ifilterfalse\n","\n","\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    p = len(gt_sorted)\n","    gts = gt_sorted.sum()\n","    intersection = gts - gt_sorted.float().cumsum(0)\n","    union = gts + (1 - gt_sorted).float().cumsum(0)\n","    jaccard = 1. - intersection / union\n","    if p > 1: # cover 1-pixel case\n","        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n","    return jaccard\n","\n","\n","def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n","    \"\"\"\n","    IoU for foreground class\n","    binary: 1 foreground, 0 background\n","    \"\"\"\n","    if not per_image:\n","        preds, labels = (preds,), (labels,)\n","    ious = []\n","    for pred, label in zip(preds, labels):\n","        intersection = ((label == 1) & (pred == 1)).sum()\n","        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n","        if not union:\n","            iou = EMPTY\n","        else:\n","            iou = float(intersection) / float(union)\n","        ious.append(iou)\n","    iou = mean(ious)    # mean accross images if per_image\n","    return 100 * iou\n","\n","\n","def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n","    \"\"\"\n","    Array of IoU for each (non ignored) class\n","    \"\"\"\n","    if not per_image:\n","        preds, labels = (preds,), (labels,)\n","    ious = []\n","    for pred, label in zip(preds, labels):\n","        iou = []    \n","        for i in range(C):\n","            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n","                intersection = ((label == i) & (pred == i)).sum()\n","                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n","                if not union:\n","                    iou.append(EMPTY)\n","                else:\n","                    iou.append(float(intersection) / float(union))\n","        ious.append(iou)\n","    ious = [mean(iou) for iou in zip(*ious)] # mean accross images if per_image\n","    return 100 * np.array(ious)\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n","                          for log, lab in zip(logits, labels))\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","    if len(labels) == 0:\n","        # only void pixels, the gradients should be 0\n","        return logits.sum() * 0.\n","    signs = 2. * labels.float() - 1.\n","    errors = (1. - logits * Variable(signs))\n","    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n","    perm = perm.data\n","    gt_sorted = labels[perm]\n","    grad = lovasz_grad(gt_sorted)\n","    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = scores.view(-1)\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return scores, labels\n","    valid = (labels != ignore)\n","    vscores = scores[valid]\n","    vlabels = labels[valid]\n","    return vscores, vlabels\n","\n","\n","class StableBCELoss(torch.nn.modules.Module):\n","    def __init__(self):\n","         super(StableBCELoss, self).__init__()\n","    def forward(self, input, target):\n","         neg_abs = - input.abs()\n","         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n","         return loss.mean()\n","\n","\n","def binary_xloss(logits, labels, ignore=None):\n","    \"\"\"\n","    Binary Cross entropy loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      ignore: void class id\n","    \"\"\"\n","    logits, labels = flatten_binary_scores(logits, labels, ignore)\n","    loss = StableBCELoss()(logits, Variable(labels.float()))\n","    return loss\n","\n","\n","# --------------------------- MULTICLASS LOSSES ---------------------------\n","\n","\n","def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n","              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n","      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n","      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class labels\n","    \"\"\"\n","    if per_image:\n","        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n","                          for prob, lab in zip(probas, labels))\n","    else:\n","        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n","    return loss\n","\n","\n","def lovasz_softmax_flat(probas, labels, classes='present'):\n","    \"\"\"\n","    Multi-class Lovasz-Softmax loss\n","      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n","      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n","      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n","    \"\"\"\n","    if probas.numel() == 0:\n","        # only void pixels, the gradients should be 0\n","        return probas * 0.\n","    C = probas.size(1)\n","    losses = []\n","    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n","    for c in class_to_sum:\n","        fg = (labels == c).float() # foreground for class c\n","        if (classes is 'present' and fg.sum() == 0):\n","            continue\n","        if C == 1:\n","            if len(classes) > 1:\n","                raise ValueError('Sigmoid output possible only with 1 class')\n","            class_pred = probas[:, 0]\n","        else:\n","            class_pred = probas[:, c]\n","        errors = (Variable(fg) - class_pred).abs()\n","        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n","        perm = perm.data\n","        fg_sorted = fg[perm]\n","        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n","    return mean(losses)\n","\n","\n","def flatten_probas(probas, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch\n","    \"\"\"\n","    if probas.dim() == 3:\n","        # assumes output of a sigmoid layer\n","        B, H, W = probas.size()\n","        probas = probas.view(B, 1, H, W)\n","    B, C, H, W = probas.size()\n","    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n","    labels = labels.view(-1)\n","    if ignore is None:\n","        return probas, labels\n","    valid = (labels != ignore)\n","    vprobas = probas[valid.nonzero().squeeze()]\n","    vlabels = labels[valid]\n","    return vprobas, vlabels\n","\n","def xloss(logits, labels, ignore=None):\n","    \"\"\"\n","    Cross entropy loss\n","    \"\"\"\n","    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n","\n","\n","# --------------------------- HELPER FUNCTIONS ---------------------------\n","def isnan(x):\n","    return x != x\n","    \n","    \n","def mean(l, ignore_nan=False, empty=0):\n","    \"\"\"\n","    nanmean compatible with generators.\n","    \"\"\"\n","    l = iter(l)\n","    if ignore_nan:\n","        l = ifilterfalse(isnan, l)\n","    try:\n","        n = 1\n","        acc = next(l)\n","    except StopIteration:\n","        if empty == 'raise':\n","            raise ValueError('Empty mean')\n","        return empty\n","    for n, v in enumerate(l, 2):\n","        acc += v\n","    if n == 1:\n","        return acc\n","    return acc / n"],"metadata":{"id":"EAFofjy4ekge","executionInfo":{"status":"ok","timestamp":1650056858457,"user_tz":240,"elapsed":1954,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["'''\n","util files\n","'''\n","def create_net(in_channels, out_channels, net_name='unet'):\n","    \"\"\"\n","    创建网络\n","    :param in_channels: 输入通道数\n","    :param out_channels: 输出通道数\n","    # :param net_name: 网络类型，可选 unet | unet_resnet18/34/50/101/152 |unet_resnext50_32x4d | deeplabv3p\n","    :param net_name: 网络类型，可选 unet | unet_resnet34\n","    \"\"\"\n","    if net_name == 'unet':\n","        net = unet(in_channels, out_channels)\n","    elif net_name == 'unet_resnet34':\n","        net = unet_resnet('resnet34', in_channels, out_channels)\n","    elif net_name == 'unet_resnet50':\n","        net = unet_resnet('resnet50', in_channels, out_channels)\n","    elif net_name == 'unet_resnet101':\n","        net = unet_resnet('resnet101', in_channels, out_channels)    \n","    elif net_name == 'resnext50_32x4d':\n","        net = unet_resnet('resnext50_32x4d', in_channels, out_channels)\n","    else:\n","        raise ValueError('Not supported net_name: {}'.format(net_name))\n","\n","    return net\n","\n","def create_loss(predicts: torch.Tensor, labels: torch.Tensor, num_classes):\n","    \"\"\"\n","    创建loss\n","    @param predicts: shape=(n, c, h, w)\n","    @param labels: shape=(n, h, w) or shape=(n, 1, h, w)\n","    @param num_classes: int should equal to channels of predicts\n","    @return: loss, mean_iou\n","    \"\"\"\n","    # permute to (n, h, w, c)\n","    predicts = predicts.permute((0, 2, 3, 1))\n","    # reshape to (-1, num_classes)  每个像素在每种分类上都有一个概率\n","    predicts = predicts.reshape((-1, num_classes))\n","    ##print(predicts.shape)\n","    ##print(labels.flatten().shape)\n","    # BCE with DICE\n","    bce_loss = F.cross_entropy(predicts, labels.flatten(), reduction='mean')  # 函数内会自动做softmax\n","    \n","    # 将labels做one_hot处理，得到的形状跟predicts相同\n","    labels_one_hot = utils.make_one_hot(labels.reshape((-1, 1)), num_classes)\n","    dice_loss = utils.DiceLoss()(predicts, labels_one_hot.to(labels.device))  # torch没有原生的，从老师给的代码里拿过来用\n","    loss = bce_loss + dice_loss\n","    #loss = bce_loss\n","    ious = compute_iou(predicts, labels.reshape((-1, 1)), num_classes)\n","    return loss, torch.mean(ious)\n","\n","def compute_iou(predicts, labels, num_classes):\n","    \"\"\"\n","    计算iou\n","    @param predicts: shape=(-1, classes)\n","    @param labels: shape=(-1, 1)\n","    \"\"\"\n","    ious = torch.zeros(num_classes)\n","    predicts = F.softmax(predicts, dim=1)\n","    predicts = torch.argmax(predicts, dim=1, keepdim=True)\n","    for i in range(num_classes):\n","        intersect = torch.sum((predicts == i) * (labels == i))\n","        area = torch.sum(predicts == i) + torch.sum(labels == i) - intersect\n","        ious[i] = intersect / (area + 1e-6)\n","    return ious\n"],"metadata":{"id":"b7tOt0NiQTyj","executionInfo":{"status":"ok","timestamp":1650056858457,"user_tz":240,"elapsed":55,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n","from torchvision import models\n","\n","\n","def createDeepLabv3(outputchannels=1):\n","    \"\"\"DeepLabv3 class with custom head\n","    Args:\n","        outputchannels (int, optional): The number of output channels\n","        in your dataset masks. Defaults to 1.\n","    Returns:\n","        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n","    \"\"\"\n","    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n","                                                    progress=True)\n","    params_to_update = []\n","    for param in model.parameters():\n","        param.requires_grad = False \n","    \n","    model.classifier = DeepLabHead(2048, outputchannels)\n","    # Set the model in training mode\n","    model.train()\n","    return model\n"],"metadata":{"id":"y2sty2Y2Zx9s","executionInfo":{"status":"ok","timestamp":1650056858458,"user_tz":240,"elapsed":55,"user":{"displayName":"xiang gao","userId":"18056195333349536450"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","@description: 执行训练\n","\"\"\"\n","\n","\n","\"\"\"\n","import\n","\"\"\"\n","#from config import ConfigTrain\n","import utils\n","from os.path import join as pjoin\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import torch\n","import time\n","\n","\"\"\"\n","main\n","\"\"\"\n","if __name__ == '__main__':\n","    cfg = ConfigTrain()\n","    print('Pick device: ', cfg.DEVICE)\n","    device = torch.device(cfg.DEVICE)\n","\n","    # 网络\n","    print('Generating net: ', \"deeplab\")\n","    net = createDeepLabv3(cfg.NUM_CLASSES)\n","\n","#     net = create_net(3, cfg.NUM_CLASSES, net_name=cfg.NET_NAME)\n","#     if cfg.PRETRAIN:  # 加载预训练权重\n","#         print('Load pretrain weights: ', cfg.PRETRAINED_WEIGHTS)\n","#         net.load_state_dict(torch.load(cfg.PRETRAINED_WEIGHTS, map_location='cpu'))\n","    net.to(device)\n","#     # 优化器\n","    optimizer = torch.optim.Adam(net.parameters(), lr=cfg.BASE_LR) \n","\n","    # 训练数据生成器\n","    print('Preparing data... batch_size: {}, image_size: {}, crop_offset: {}'.format(cfg.BATCH_SIZE, cfg.IMAGE_SIZE, cfg.HEIGHT_CROP_OFFSET))\n","    df_train = pd.read_csv(pjoin(cfg.DATA_LIST_ROOT, 'train.csv'))\n","    data_generator = utils.train_data_generator(np.array(df_train['image']),\n","                                                np.array(df_train['label']),\n","                                                cfg.BATCH_SIZE, cfg.IMAGE_SIZE, cfg.HEIGHT_CROP_OFFSET)\n","\n","    # 训练\n","    print('Let us train ...')\n","    log_iters = 1  # 多少次迭代打印一次log\n","    epoch_size = int(len(df_train) / cfg.BATCH_SIZE)  # 一个轮次包含的迭代次数\n","    ##trn_loss_hist = []\n","    ##iou_hist = []\n","    loss_plot = []\n","    iou_plot = []\n","    for epoch in range(cfg.EPOCH_BEGIN, cfg.EPOCH_NUM):\n","        epoch_loss = 0.0\n","        epoch_miou = 0.0\n","        last_epoch_miou = 0.0\n","        prev_time = time.time()\n","        for iteration in range(1 , epoch_size + 1):\n","            images, labels, images_filename = next(data_generator)\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            lr = utils.ajust_learning_rate(optimizer, cfg.LR_STRATEGY, epoch, iteration-1, epoch_size)\n","\n","            output = net(images)\n","            predicts = output[\"out\"]\n","            print(predicts.shape)\n","            optimizer.zero_grad()\n","\n","            # # create loss\n","            cross_loss, mean_iou = utils.create_loss(predicts, labels, cfg.NUM_CLASSES)\n","            # #iou = utils.iou(predicts, labels, 3,ignore=255, per_image=True)\n","            # predicts =  torch.nn.functional.softmax(predicts,dim=1)\n","            # #f_loss = focal_loss(predicts,labels)\n","            \n","            # loss_lovasz_softmax = utils.lovasz_softmax(predicts, labels)\n","            loss = cross_loss;\n","\n","            epoch_loss += loss.item()\n","            epoch_miou += mean_iou.item()\n","\n","            print(\"[Epoch-%d Iter-%d] LR: %.4f: iter loss: %.3f, iter iou: %.3f, epoch loss: %.3f, epoch iou: %.3f,  time cost: %.3f s\"\n","                % (epoch, iteration, lr, loss.item(), mean_iou.item(), epoch_loss / iteration, epoch_miou / iteration, time.time() - prev_time))\n","            prev_time = time.time()\n","\n","            # # if mean_iou.item() < last_epoch_miou * cfg.SUSPICIOUS_RATE:\n","            # #   ## TO DO: define log file or create a log file##\n","            # #     with open(cfg.LOG_SUSPICIOUS_FILES, 'a+') as f:\n","            # #         for filename in images_filename:\n","            # #             f.write(\"{}\\n\".format(filename))\n","            # #         f.flush()\n","\n","            last_epoch_miou = epoch_miou / iteration\n","            \n","            loss.backward()\n","            loss_plot.append(loss.item())\n","            iou_plot.append(mean_iou.item())\n","            optimizer.step()\n","\n","        torch.save(net.state_dict(), \n","                    pjoin(cfg.WEIGHTS_SAVE_ROOT, \"weights_ep_%d_%.3f_%.3f.pth\" \n","                            % (epoch, epoch_loss / epoch_size, epoch_miou / epoch_size)))\n","    \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gl-yCIdGOCQN","outputId":"32d99ec8-2fc6-4264-c5ad-2fe366cf4c94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pick device:  cuda\n","Generating net:  deeplab\n","Preparing data... batch_size: 2, image_size: (768, 256), crop_offset: 690\n","Let us train ...\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-1] LR: 0.0010: iter loss: 2.091, iter iou: 0.010, epoch loss: 2.091, epoch iou: 0.010,  time cost: 52.539 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-2] LR: 0.0010: iter loss: 1.944, iter iou: 0.045, epoch loss: 2.017, epoch iou: 0.028,  time cost: 54.219 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-3] LR: 0.0010: iter loss: 1.892, iter iou: 0.058, epoch loss: 1.975, epoch iou: 0.038,  time cost: 52.154 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-4] LR: 0.0010: iter loss: 1.695, iter iou: 0.064, epoch loss: 1.905, epoch iou: 0.044,  time cost: 54.613 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-5] LR: 0.0010: iter loss: 1.417, iter iou: 0.089, epoch loss: 1.808, epoch iou: 0.053,  time cost: 51.809 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-6] LR: 0.0010: iter loss: 1.244, iter iou: 0.113, epoch loss: 1.714, epoch iou: 0.063,  time cost: 52.183 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-7] LR: 0.0010: iter loss: 1.071, iter iou: 0.116, epoch loss: 1.622, epoch iou: 0.071,  time cost: 52.225 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-8] LR: 0.0010: iter loss: 0.888, iter iou: 0.124, epoch loss: 1.530, epoch iou: 0.077,  time cost: 51.977 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-9] LR: 0.0010: iter loss: 0.753, iter iou: 0.122, epoch loss: 1.444, epoch iou: 0.082,  time cost: 52.201 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-10] LR: 0.0010: iter loss: 0.623, iter iou: 0.123, epoch loss: 1.362, epoch iou: 0.086,  time cost: 52.050 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-11] LR: 0.0010: iter loss: 0.549, iter iou: 0.121, epoch loss: 1.288, epoch iou: 0.090,  time cost: 53.369 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-12] LR: 0.0010: iter loss: 0.477, iter iou: 0.122, epoch loss: 1.220, epoch iou: 0.092,  time cost: 51.294 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-13] LR: 0.0010: iter loss: 0.416, iter iou: 0.122, epoch loss: 1.158, epoch iou: 0.094,  time cost: 51.114 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-14] LR: 0.0010: iter loss: 0.339, iter iou: 0.124, epoch loss: 1.100, epoch iou: 0.097,  time cost: 51.134 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-15] LR: 0.0010: iter loss: 0.473, iter iou: 0.116, epoch loss: 1.058, epoch iou: 0.098,  time cost: 50.925 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-16] LR: 0.0010: iter loss: 0.235, iter iou: 0.124, epoch loss: 1.007, epoch iou: 0.099,  time cost: 49.481 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-17] LR: 0.0010: iter loss: 0.242, iter iou: 0.123, epoch loss: 0.962, epoch iou: 0.101,  time cost: 51.449 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-18] LR: 0.0010: iter loss: 0.212, iter iou: 0.123, epoch loss: 0.920, epoch iou: 0.102,  time cost: 51.517 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-19] LR: 0.0010: iter loss: 0.202, iter iou: 0.123, epoch loss: 0.882, epoch iou: 0.103,  time cost: 51.242 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-20] LR: 0.0010: iter loss: 0.166, iter iou: 0.123, epoch loss: 0.846, epoch iou: 0.104,  time cost: 49.755 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-21] LR: 0.0010: iter loss: 0.153, iter iou: 0.123, epoch loss: 0.813, epoch iou: 0.105,  time cost: 51.497 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-22] LR: 0.0010: iter loss: 0.383, iter iou: 0.116, epoch loss: 0.794, epoch iou: 0.106,  time cost: 51.077 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-23] LR: 0.0010: iter loss: 0.173, iter iou: 0.122, epoch loss: 0.767, epoch iou: 0.106,  time cost: 51.511 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-24] LR: 0.0010: iter loss: 0.157, iter iou: 0.123, epoch loss: 0.741, epoch iou: 0.107,  time cost: 49.647 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-25] LR: 0.0010: iter loss: 0.138, iter iou: 0.123, epoch loss: 0.717, epoch iou: 0.108,  time cost: 51.390 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-26] LR: 0.0010: iter loss: 0.184, iter iou: 0.121, epoch loss: 0.697, epoch iou: 0.108,  time cost: 51.297 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-27] LR: 0.0010: iter loss: 0.166, iter iou: 0.121, epoch loss: 0.677, epoch iou: 0.109,  time cost: 51.780 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-28] LR: 0.0010: iter loss: 0.432, iter iou: 0.115, epoch loss: 0.668, epoch iou: 0.109,  time cost: 49.513 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-29] LR: 0.0010: iter loss: 0.122, iter iou: 0.123, epoch loss: 0.649, epoch iou: 0.109,  time cost: 51.110 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-30] LR: 0.0010: iter loss: 0.160, iter iou: 0.122, epoch loss: 0.633, epoch iou: 0.110,  time cost: 51.394 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-31] LR: 0.0010: iter loss: 0.113, iter iou: 0.123, epoch loss: 0.616, epoch iou: 0.110,  time cost: 51.026 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-32] LR: 0.0010: iter loss: 0.174, iter iou: 0.127, epoch loss: 0.603, epoch iou: 0.111,  time cost: 49.025 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-33] LR: 0.0010: iter loss: 0.451, iter iou: 0.134, epoch loss: 0.598, epoch iou: 0.111,  time cost: 51.113 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-34] LR: 0.0010: iter loss: 0.099, iter iou: 0.123, epoch loss: 0.583, epoch iou: 0.112,  time cost: 51.229 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-35] LR: 0.0010: iter loss: 0.088, iter iou: 0.123, epoch loss: 0.569, epoch iou: 0.112,  time cost: 51.054 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-36] LR: 0.0010: iter loss: 0.108, iter iou: 0.123, epoch loss: 0.556, epoch iou: 0.112,  time cost: 50.242 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-37] LR: 0.0010: iter loss: 0.433, iter iou: 0.114, epoch loss: 0.553, epoch iou: 0.112,  time cost: 51.119 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-38] LR: 0.0010: iter loss: 0.272, iter iou: 0.120, epoch loss: 0.546, epoch iou: 0.113,  time cost: 50.947 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-39] LR: 0.0010: iter loss: 0.101, iter iou: 0.123, epoch loss: 0.534, epoch iou: 0.113,  time cost: 51.005 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-40] LR: 0.0010: iter loss: 0.092, iter iou: 0.123, epoch loss: 0.523, epoch iou: 0.113,  time cost: 49.256 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-41] LR: 0.0010: iter loss: 0.140, iter iou: 0.122, epoch loss: 0.514, epoch iou: 0.113,  time cost: 50.993 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-42] LR: 0.0010: iter loss: 0.126, iter iou: 0.123, epoch loss: 0.505, epoch iou: 0.114,  time cost: 50.870 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-43] LR: 0.0010: iter loss: 0.179, iter iou: 0.120, epoch loss: 0.497, epoch iou: 0.114,  time cost: 51.136 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-44] LR: 0.0010: iter loss: 0.206, iter iou: 0.120, epoch loss: 0.490, epoch iou: 0.114,  time cost: 49.464 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-45] LR: 0.0010: iter loss: 0.239, iter iou: 0.130, epoch loss: 0.485, epoch iou: 0.114,  time cost: 50.938 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-46] LR: 0.0010: iter loss: 0.092, iter iou: 0.129, epoch loss: 0.476, epoch iou: 0.115,  time cost: 52.336 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-47] LR: 0.0010: iter loss: 0.111, iter iou: 0.127, epoch loss: 0.468, epoch iou: 0.115,  time cost: 51.160 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-48] LR: 0.0010: iter loss: 0.089, iter iou: 0.123, epoch loss: 0.461, epoch iou: 0.115,  time cost: 49.295 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-49] LR: 0.0010: iter loss: 0.129, iter iou: 0.133, epoch loss: 0.454, epoch iou: 0.115,  time cost: 51.813 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-50] LR: 0.0010: iter loss: 0.079, iter iou: 0.127, epoch loss: 0.446, epoch iou: 0.116,  time cost: 51.954 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-51] LR: 0.0010: iter loss: 0.178, iter iou: 0.128, epoch loss: 0.441, epoch iou: 0.116,  time cost: 51.861 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-52] LR: 0.0010: iter loss: 0.132, iter iou: 0.123, epoch loss: 0.435, epoch iou: 0.116,  time cost: 50.243 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-53] LR: 0.0010: iter loss: 0.111, iter iou: 0.123, epoch loss: 0.429, epoch iou: 0.116,  time cost: 52.302 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-54] LR: 0.0010: iter loss: 0.065, iter iou: 0.124, epoch loss: 0.422, epoch iou: 0.116,  time cost: 52.164 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-55] LR: 0.0010: iter loss: 0.113, iter iou: 0.122, epoch loss: 0.417, epoch iou: 0.116,  time cost: 52.830 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-56] LR: 0.0010: iter loss: 0.107, iter iou: 0.138, epoch loss: 0.411, epoch iou: 0.117,  time cost: 51.336 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-57] LR: 0.0010: iter loss: 0.093, iter iou: 0.154, epoch loss: 0.405, epoch iou: 0.117,  time cost: 54.404 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-58] LR: 0.0010: iter loss: 0.064, iter iou: 0.161, epoch loss: 0.400, epoch iou: 0.118,  time cost: 52.925 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-59] LR: 0.0010: iter loss: 0.119, iter iou: 0.146, epoch loss: 0.395, epoch iou: 0.119,  time cost: 52.262 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-60] LR: 0.0010: iter loss: 0.159, iter iou: 0.138, epoch loss: 0.391, epoch iou: 0.119,  time cost: 50.143 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-61] LR: 0.0010: iter loss: 0.116, iter iou: 0.132, epoch loss: 0.386, epoch iou: 0.119,  time cost: 52.514 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-62] LR: 0.0010: iter loss: 0.133, iter iou: 0.125, epoch loss: 0.382, epoch iou: 0.119,  time cost: 52.956 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-63] LR: 0.0010: iter loss: 0.233, iter iou: 0.139, epoch loss: 0.380, epoch iou: 0.120,  time cost: 52.911 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-64] LR: 0.0010: iter loss: 0.070, iter iou: 0.148, epoch loss: 0.375, epoch iou: 0.120,  time cost: 50.468 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-65] LR: 0.0010: iter loss: 0.060, iter iou: 0.128, epoch loss: 0.370, epoch iou: 0.120,  time cost: 52.435 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-66] LR: 0.0010: iter loss: 0.333, iter iou: 0.128, epoch loss: 0.370, epoch iou: 0.120,  time cost: 52.717 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-67] LR: 0.0010: iter loss: 0.074, iter iou: 0.156, epoch loss: 0.365, epoch iou: 0.121,  time cost: 52.552 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-68] LR: 0.0010: iter loss: 0.083, iter iou: 0.138, epoch loss: 0.361, epoch iou: 0.121,  time cost: 50.145 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-69] LR: 0.0010: iter loss: 0.271, iter iou: 0.118, epoch loss: 0.360, epoch iou: 0.121,  time cost: 53.375 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-70] LR: 0.0010: iter loss: 0.094, iter iou: 0.143, epoch loss: 0.356, epoch iou: 0.121,  time cost: 50.429 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-71] LR: 0.0010: iter loss: 0.055, iter iou: 0.145, epoch loss: 0.352, epoch iou: 0.122,  time cost: 50.752 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-72] LR: 0.0010: iter loss: 0.124, iter iou: 0.138, epoch loss: 0.349, epoch iou: 0.122,  time cost: 50.383 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-73] LR: 0.0010: iter loss: 0.104, iter iou: 0.125, epoch loss: 0.345, epoch iou: 0.122,  time cost: 53.583 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-74] LR: 0.0010: iter loss: 0.084, iter iou: 0.123, epoch loss: 0.342, epoch iou: 0.122,  time cost: 51.715 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-75] LR: 0.0010: iter loss: 0.072, iter iou: 0.124, epoch loss: 0.338, epoch iou: 0.122,  time cost: 51.859 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-76] LR: 0.0010: iter loss: 0.044, iter iou: 0.128, epoch loss: 0.334, epoch iou: 0.122,  time cost: 50.192 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-77] LR: 0.0010: iter loss: 0.104, iter iou: 0.130, epoch loss: 0.331, epoch iou: 0.122,  time cost: 53.374 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-78] LR: 0.0010: iter loss: 0.199, iter iou: 0.128, epoch loss: 0.330, epoch iou: 0.122,  time cost: 51.065 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-79] LR: 0.0010: iter loss: 0.088, iter iou: 0.129, epoch loss: 0.327, epoch iou: 0.122,  time cost: 51.993 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-80] LR: 0.0010: iter loss: 0.070, iter iou: 0.147, epoch loss: 0.323, epoch iou: 0.123,  time cost: 49.356 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-81] LR: 0.0010: iter loss: 0.092, iter iou: 0.133, epoch loss: 0.320, epoch iou: 0.123,  time cost: 50.651 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-82] LR: 0.0010: iter loss: 0.296, iter iou: 0.139, epoch loss: 0.320, epoch iou: 0.123,  time cost: 51.379 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-83] LR: 0.0010: iter loss: 0.232, iter iou: 0.120, epoch loss: 0.319, epoch iou: 0.123,  time cost: 51.694 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-84] LR: 0.0010: iter loss: 0.070, iter iou: 0.136, epoch loss: 0.316, epoch iou: 0.123,  time cost: 50.808 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-85] LR: 0.0010: iter loss: 0.254, iter iou: 0.135, epoch loss: 0.315, epoch iou: 0.123,  time cost: 52.288 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-86] LR: 0.0010: iter loss: 0.167, iter iou: 0.145, epoch loss: 0.314, epoch iou: 0.123,  time cost: 51.911 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-87] LR: 0.0010: iter loss: 0.176, iter iou: 0.151, epoch loss: 0.312, epoch iou: 0.124,  time cost: 52.149 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-88] LR: 0.0010: iter loss: 0.156, iter iou: 0.161, epoch loss: 0.310, epoch iou: 0.124,  time cost: 49.957 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-89] LR: 0.0010: iter loss: 0.094, iter iou: 0.153, epoch loss: 0.308, epoch iou: 0.125,  time cost: 51.879 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-90] LR: 0.0010: iter loss: 0.108, iter iou: 0.176, epoch loss: 0.306, epoch iou: 0.125,  time cost: 51.812 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-91] LR: 0.0010: iter loss: 0.092, iter iou: 0.154, epoch loss: 0.303, epoch iou: 0.125,  time cost: 50.434 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-92] LR: 0.0010: iter loss: 0.077, iter iou: 0.142, epoch loss: 0.301, epoch iou: 0.126,  time cost: 49.285 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-93] LR: 0.0010: iter loss: 0.077, iter iou: 0.132, epoch loss: 0.298, epoch iou: 0.126,  time cost: 51.860 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-94] LR: 0.0010: iter loss: 0.113, iter iou: 0.146, epoch loss: 0.296, epoch iou: 0.126,  time cost: 51.644 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-95] LR: 0.0010: iter loss: 0.178, iter iou: 0.122, epoch loss: 0.295, epoch iou: 0.126,  time cost: 51.933 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-96] LR: 0.0010: iter loss: 0.298, iter iou: 0.121, epoch loss: 0.295, epoch iou: 0.126,  time cost: 50.139 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-97] LR: 0.0010: iter loss: 0.103, iter iou: 0.134, epoch loss: 0.293, epoch iou: 0.126,  time cost: 52.978 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-98] LR: 0.0010: iter loss: 0.198, iter iou: 0.145, epoch loss: 0.292, epoch iou: 0.126,  time cost: 52.400 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-99] LR: 0.0010: iter loss: 0.132, iter iou: 0.125, epoch loss: 0.291, epoch iou: 0.126,  time cost: 51.907 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-100] LR: 0.0010: iter loss: 0.097, iter iou: 0.136, epoch loss: 0.289, epoch iou: 0.126,  time cost: 51.538 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-101] LR: 0.0010: iter loss: 0.102, iter iou: 0.133, epoch loss: 0.287, epoch iou: 0.126,  time cost: 51.340 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-102] LR: 0.0010: iter loss: 0.088, iter iou: 0.136, epoch loss: 0.285, epoch iou: 0.126,  time cost: 50.390 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-103] LR: 0.0010: iter loss: 0.080, iter iou: 0.181, epoch loss: 0.283, epoch iou: 0.127,  time cost: 53.119 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-104] LR: 0.0010: iter loss: 0.070, iter iou: 0.157, epoch loss: 0.281, epoch iou: 0.127,  time cost: 50.252 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-105] LR: 0.0010: iter loss: 0.116, iter iou: 0.153, epoch loss: 0.279, epoch iou: 0.127,  time cost: 52.136 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-106] LR: 0.0010: iter loss: 0.117, iter iou: 0.155, epoch loss: 0.278, epoch iou: 0.128,  time cost: 51.454 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-107] LR: 0.0010: iter loss: 0.147, iter iou: 0.167, epoch loss: 0.277, epoch iou: 0.128,  time cost: 50.932 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-108] LR: 0.0010: iter loss: 0.091, iter iou: 0.127, epoch loss: 0.275, epoch iou: 0.128,  time cost: 50.156 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-109] LR: 0.0010: iter loss: 0.121, iter iou: 0.150, epoch loss: 0.273, epoch iou: 0.128,  time cost: 51.585 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-110] LR: 0.0010: iter loss: 0.154, iter iou: 0.136, epoch loss: 0.272, epoch iou: 0.128,  time cost: 51.857 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-111] LR: 0.0010: iter loss: 0.039, iter iou: 0.125, epoch loss: 0.270, epoch iou: 0.128,  time cost: 51.766 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-112] LR: 0.0010: iter loss: 0.209, iter iou: 0.137, epoch loss: 0.270, epoch iou: 0.128,  time cost: 50.272 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-113] LR: 0.0010: iter loss: 0.186, iter iou: 0.120, epoch loss: 0.269, epoch iou: 0.128,  time cost: 50.809 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-114] LR: 0.0010: iter loss: 0.256, iter iou: 0.142, epoch loss: 0.269, epoch iou: 0.128,  time cost: 52.962 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-115] LR: 0.0010: iter loss: 0.245, iter iou: 0.119, epoch loss: 0.269, epoch iou: 0.128,  time cost: 52.073 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-116] LR: 0.0010: iter loss: 0.085, iter iou: 0.124, epoch loss: 0.267, epoch iou: 0.128,  time cost: 50.073 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-117] LR: 0.0010: iter loss: 0.127, iter iou: 0.127, epoch loss: 0.266, epoch iou: 0.128,  time cost: 51.982 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-118] LR: 0.0010: iter loss: 0.075, iter iou: 0.124, epoch loss: 0.264, epoch iou: 0.128,  time cost: 51.899 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-119] LR: 0.0010: iter loss: 0.100, iter iou: 0.125, epoch loss: 0.263, epoch iou: 0.128,  time cost: 51.530 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-120] LR: 0.0010: iter loss: 0.120, iter iou: 0.128, epoch loss: 0.262, epoch iou: 0.128,  time cost: 50.009 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-121] LR: 0.0010: iter loss: 0.112, iter iou: 0.124, epoch loss: 0.260, epoch iou: 0.128,  time cost: 51.388 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-122] LR: 0.0010: iter loss: 0.130, iter iou: 0.141, epoch loss: 0.259, epoch iou: 0.128,  time cost: 51.229 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-123] LR: 0.0010: iter loss: 0.058, iter iou: 0.138, epoch loss: 0.258, epoch iou: 0.128,  time cost: 50.238 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-124] LR: 0.0010: iter loss: 0.059, iter iou: 0.131, epoch loss: 0.256, epoch iou: 0.128,  time cost: 49.370 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-125] LR: 0.0010: iter loss: 0.080, iter iou: 0.123, epoch loss: 0.255, epoch iou: 0.128,  time cost: 51.834 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-126] LR: 0.0010: iter loss: 0.071, iter iou: 0.137, epoch loss: 0.253, epoch iou: 0.128,  time cost: 51.597 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-127] LR: 0.0010: iter loss: 0.060, iter iou: 0.143, epoch loss: 0.252, epoch iou: 0.128,  time cost: 53.022 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-128] LR: 0.0010: iter loss: 0.249, iter iou: 0.123, epoch loss: 0.252, epoch iou: 0.128,  time cost: 50.009 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-129] LR: 0.0010: iter loss: 0.194, iter iou: 0.133, epoch loss: 0.251, epoch iou: 0.128,  time cost: 51.775 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-130] LR: 0.0010: iter loss: 0.147, iter iou: 0.151, epoch loss: 0.250, epoch iou: 0.129,  time cost: 51.602 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-131] LR: 0.0010: iter loss: 0.131, iter iou: 0.157, epoch loss: 0.250, epoch iou: 0.129,  time cost: 51.328 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-132] LR: 0.0010: iter loss: 0.271, iter iou: 0.148, epoch loss: 0.250, epoch iou: 0.129,  time cost: 51.492 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-133] LR: 0.0010: iter loss: 0.213, iter iou: 0.136, epoch loss: 0.249, epoch iou: 0.129,  time cost: 50.846 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-134] LR: 0.0010: iter loss: 0.071, iter iou: 0.150, epoch loss: 0.248, epoch iou: 0.129,  time cost: 50.260 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-135] LR: 0.0010: iter loss: 0.084, iter iou: 0.158, epoch loss: 0.247, epoch iou: 0.129,  time cost: 51.598 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-136] LR: 0.0010: iter loss: 0.073, iter iou: 0.169, epoch loss: 0.246, epoch iou: 0.130,  time cost: 51.176 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-137] LR: 0.0010: iter loss: 0.091, iter iou: 0.167, epoch loss: 0.244, epoch iou: 0.130,  time cost: 51.791 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-138] LR: 0.0010: iter loss: 0.094, iter iou: 0.156, epoch loss: 0.243, epoch iou: 0.130,  time cost: 51.554 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-139] LR: 0.0010: iter loss: 0.050, iter iou: 0.151, epoch loss: 0.242, epoch iou: 0.130,  time cost: 53.108 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-140] LR: 0.0010: iter loss: 0.037, iter iou: 0.148, epoch loss: 0.241, epoch iou: 0.130,  time cost: 50.536 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-141] LR: 0.0010: iter loss: 0.071, iter iou: 0.128, epoch loss: 0.239, epoch iou: 0.130,  time cost: 51.419 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-142] LR: 0.0010: iter loss: 0.067, iter iou: 0.125, epoch loss: 0.238, epoch iou: 0.130,  time cost: 51.517 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-143] LR: 0.0010: iter loss: 0.222, iter iou: 0.116, epoch loss: 0.238, epoch iou: 0.130,  time cost: 51.413 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-144] LR: 0.0010: iter loss: 0.143, iter iou: 0.121, epoch loss: 0.237, epoch iou: 0.130,  time cost: 49.132 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-145] LR: 0.0010: iter loss: 0.055, iter iou: 0.125, epoch loss: 0.236, epoch iou: 0.130,  time cost: 51.100 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-146] LR: 0.0010: iter loss: 0.257, iter iou: 0.118, epoch loss: 0.236, epoch iou: 0.130,  time cost: 51.685 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-147] LR: 0.0010: iter loss: 0.151, iter iou: 0.134, epoch loss: 0.236, epoch iou: 0.130,  time cost: 51.836 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-148] LR: 0.0010: iter loss: 0.085, iter iou: 0.128, epoch loss: 0.235, epoch iou: 0.130,  time cost: 49.956 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-149] LR: 0.0010: iter loss: 0.194, iter iou: 0.127, epoch loss: 0.234, epoch iou: 0.130,  time cost: 51.669 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-150] LR: 0.0010: iter loss: 0.134, iter iou: 0.163, epoch loss: 0.234, epoch iou: 0.130,  time cost: 51.697 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-151] LR: 0.0010: iter loss: 0.115, iter iou: 0.175, epoch loss: 0.233, epoch iou: 0.131,  time cost: 51.860 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-152] LR: 0.0010: iter loss: 0.150, iter iou: 0.150, epoch loss: 0.232, epoch iou: 0.131,  time cost: 50.119 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-153] LR: 0.0010: iter loss: 0.086, iter iou: 0.161, epoch loss: 0.231, epoch iou: 0.131,  time cost: 50.489 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-154] LR: 0.0010: iter loss: 0.096, iter iou: 0.168, epoch loss: 0.231, epoch iou: 0.131,  time cost: 50.642 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-155] LR: 0.0010: iter loss: 0.103, iter iou: 0.174, epoch loss: 0.230, epoch iou: 0.131,  time cost: 50.409 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-156] LR: 0.0010: iter loss: 0.079, iter iou: 0.149, epoch loss: 0.229, epoch iou: 0.132,  time cost: 50.516 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-157] LR: 0.0010: iter loss: 0.135, iter iou: 0.146, epoch loss: 0.228, epoch iou: 0.132,  time cost: 51.509 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-158] LR: 0.0010: iter loss: 0.220, iter iou: 0.155, epoch loss: 0.228, epoch iou: 0.132,  time cost: 51.569 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-159] LR: 0.0010: iter loss: 0.094, iter iou: 0.132, epoch loss: 0.227, epoch iou: 0.132,  time cost: 51.586 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-160] LR: 0.0010: iter loss: 0.080, iter iou: 0.158, epoch loss: 0.226, epoch iou: 0.132,  time cost: 49.667 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-161] LR: 0.0010: iter loss: 0.067, iter iou: 0.158, epoch loss: 0.225, epoch iou: 0.132,  time cost: 53.674 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-162] LR: 0.0010: iter loss: 0.261, iter iou: 0.125, epoch loss: 0.226, epoch iou: 0.132,  time cost: 51.530 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-163] LR: 0.0010: iter loss: 0.079, iter iou: 0.146, epoch loss: 0.225, epoch iou: 0.132,  time cost: 51.932 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-164] LR: 0.0010: iter loss: 0.088, iter iou: 0.124, epoch loss: 0.224, epoch iou: 0.132,  time cost: 49.814 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-165] LR: 0.0010: iter loss: 0.141, iter iou: 0.139, epoch loss: 0.223, epoch iou: 0.132,  time cost: 50.612 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-166] LR: 0.0010: iter loss: 0.072, iter iou: 0.128, epoch loss: 0.222, epoch iou: 0.132,  time cost: 50.536 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-167] LR: 0.0010: iter loss: 0.156, iter iou: 0.121, epoch loss: 0.222, epoch iou: 0.132,  time cost: 52.829 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-168] LR: 0.0010: iter loss: 0.103, iter iou: 0.127, epoch loss: 0.221, epoch iou: 0.132,  time cost: 50.169 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-169] LR: 0.0010: iter loss: 0.108, iter iou: 0.124, epoch loss: 0.221, epoch iou: 0.132,  time cost: 51.790 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-170] LR: 0.0010: iter loss: 0.081, iter iou: 0.147, epoch loss: 0.220, epoch iou: 0.132,  time cost: 53.291 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-171] LR: 0.0010: iter loss: 0.062, iter iou: 0.149, epoch loss: 0.219, epoch iou: 0.132,  time cost: 52.069 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-172] LR: 0.0010: iter loss: 0.056, iter iou: 0.159, epoch loss: 0.218, epoch iou: 0.132,  time cost: 49.802 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-173] LR: 0.0010: iter loss: 0.071, iter iou: 0.133, epoch loss: 0.217, epoch iou: 0.132,  time cost: 52.177 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-174] LR: 0.0010: iter loss: 0.112, iter iou: 0.171, epoch loss: 0.216, epoch iou: 0.133,  time cost: 53.292 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-175] LR: 0.0010: iter loss: 0.048, iter iou: 0.153, epoch loss: 0.216, epoch iou: 0.133,  time cost: 50.995 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-176] LR: 0.0010: iter loss: 0.151, iter iou: 0.151, epoch loss: 0.215, epoch iou: 0.133,  time cost: 49.296 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-177] LR: 0.0010: iter loss: 0.051, iter iou: 0.125, epoch loss: 0.214, epoch iou: 0.133,  time cost: 51.582 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-178] LR: 0.0010: iter loss: 0.051, iter iou: 0.164, epoch loss: 0.213, epoch iou: 0.133,  time cost: 51.971 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-179] LR: 0.0010: iter loss: 0.116, iter iou: 0.144, epoch loss: 0.213, epoch iou: 0.133,  time cost: 51.532 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-180] LR: 0.0010: iter loss: 0.191, iter iou: 0.172, epoch loss: 0.213, epoch iou: 0.133,  time cost: 50.042 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-181] LR: 0.0010: iter loss: 0.072, iter iou: 0.123, epoch loss: 0.212, epoch iou: 0.133,  time cost: 53.230 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-182] LR: 0.0010: iter loss: 0.241, iter iou: 0.185, epoch loss: 0.212, epoch iou: 0.133,  time cost: 51.936 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-183] LR: 0.0010: iter loss: 0.069, iter iou: 0.163, epoch loss: 0.211, epoch iou: 0.134,  time cost: 52.080 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-184] LR: 0.0010: iter loss: 0.077, iter iou: 0.150, epoch loss: 0.211, epoch iou: 0.134,  time cost: 50.544 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-185] LR: 0.0010: iter loss: 0.282, iter iou: 0.163, epoch loss: 0.211, epoch iou: 0.134,  time cost: 51.783 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-186] LR: 0.0010: iter loss: 0.144, iter iou: 0.150, epoch loss: 0.211, epoch iou: 0.134,  time cost: 50.679 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-187] LR: 0.0010: iter loss: 0.075, iter iou: 0.147, epoch loss: 0.210, epoch iou: 0.134,  time cost: 50.847 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-188] LR: 0.0010: iter loss: 0.062, iter iou: 0.124, epoch loss: 0.209, epoch iou: 0.134,  time cost: 49.959 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-189] LR: 0.0010: iter loss: 0.084, iter iou: 0.149, epoch loss: 0.208, epoch iou: 0.134,  time cost: 52.062 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-190] LR: 0.0010: iter loss: 0.063, iter iou: 0.153, epoch loss: 0.208, epoch iou: 0.134,  time cost: 51.534 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-191] LR: 0.0010: iter loss: 0.386, iter iou: 0.118, epoch loss: 0.209, epoch iou: 0.134,  time cost: 51.573 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-192] LR: 0.0010: iter loss: 0.115, iter iou: 0.176, epoch loss: 0.208, epoch iou: 0.134,  time cost: 51.618 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-193] LR: 0.0010: iter loss: 0.118, iter iou: 0.155, epoch loss: 0.208, epoch iou: 0.134,  time cost: 51.841 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-194] LR: 0.0010: iter loss: 0.126, iter iou: 0.202, epoch loss: 0.207, epoch iou: 0.135,  time cost: 51.779 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-195] LR: 0.0010: iter loss: 0.093, iter iou: 0.147, epoch loss: 0.207, epoch iou: 0.135,  time cost: 51.795 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-196] LR: 0.0010: iter loss: 0.154, iter iou: 0.151, epoch loss: 0.206, epoch iou: 0.135,  time cost: 50.924 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-197] LR: 0.0010: iter loss: 0.093, iter iou: 0.131, epoch loss: 0.206, epoch iou: 0.135,  time cost: 50.210 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-198] LR: 0.0010: iter loss: 0.081, iter iou: 0.150, epoch loss: 0.205, epoch iou: 0.135,  time cost: 51.546 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-199] LR: 0.0010: iter loss: 0.116, iter iou: 0.132, epoch loss: 0.205, epoch iou: 0.135,  time cost: 51.706 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-200] LR: 0.0010: iter loss: 0.087, iter iou: 0.126, epoch loss: 0.204, epoch iou: 0.135,  time cost: 50.028 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-201] LR: 0.0010: iter loss: 0.254, iter iou: 0.146, epoch loss: 0.204, epoch iou: 0.135,  time cost: 51.898 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-202] LR: 0.0010: iter loss: 0.129, iter iou: 0.155, epoch loss: 0.204, epoch iou: 0.135,  time cost: 51.873 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-203] LR: 0.0010: iter loss: 0.099, iter iou: 0.173, epoch loss: 0.203, epoch iou: 0.135,  time cost: 51.562 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-204] LR: 0.0010: iter loss: 0.065, iter iou: 0.166, epoch loss: 0.203, epoch iou: 0.135,  time cost: 49.925 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-205] LR: 0.0010: iter loss: 0.049, iter iou: 0.124, epoch loss: 0.202, epoch iou: 0.135,  time cost: 51.794 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-206] LR: 0.0010: iter loss: 0.040, iter iou: 0.165, epoch loss: 0.201, epoch iou: 0.135,  time cost: 51.584 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-207] LR: 0.0010: iter loss: 0.211, iter iou: 0.143, epoch loss: 0.201, epoch iou: 0.135,  time cost: 51.569 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-208] LR: 0.0010: iter loss: 0.055, iter iou: 0.177, epoch loss: 0.201, epoch iou: 0.136,  time cost: 51.189 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-209] LR: 0.0010: iter loss: 0.045, iter iou: 0.167, epoch loss: 0.200, epoch iou: 0.136,  time cost: 51.727 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-210] LR: 0.0010: iter loss: 0.243, iter iou: 0.157, epoch loss: 0.200, epoch iou: 0.136,  time cost: 52.230 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-211] LR: 0.0010: iter loss: 0.080, iter iou: 0.158, epoch loss: 0.199, epoch iou: 0.136,  time cost: 51.509 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-212] LR: 0.0010: iter loss: 0.095, iter iou: 0.177, epoch loss: 0.199, epoch iou: 0.136,  time cost: 51.545 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-213] LR: 0.0010: iter loss: 0.081, iter iou: 0.174, epoch loss: 0.198, epoch iou: 0.136,  time cost: 51.508 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-214] LR: 0.0010: iter loss: 0.111, iter iou: 0.153, epoch loss: 0.198, epoch iou: 0.136,  time cost: 52.064 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-215] LR: 0.0010: iter loss: 0.185, iter iou: 0.159, epoch loss: 0.198, epoch iou: 0.137,  time cost: 51.615 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-216] LR: 0.0010: iter loss: 0.078, iter iou: 0.162, epoch loss: 0.197, epoch iou: 0.137,  time cost: 50.371 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-217] LR: 0.0010: iter loss: 0.152, iter iou: 0.148, epoch loss: 0.197, epoch iou: 0.137,  time cost: 50.825 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-218] LR: 0.0010: iter loss: 0.182, iter iou: 0.136, epoch loss: 0.197, epoch iou: 0.137,  time cost: 50.480 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-219] LR: 0.0010: iter loss: 0.302, iter iou: 0.135, epoch loss: 0.198, epoch iou: 0.137,  time cost: 52.128 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-220] LR: 0.0010: iter loss: 0.075, iter iou: 0.159, epoch loss: 0.197, epoch iou: 0.137,  time cost: 49.815 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-221] LR: 0.0010: iter loss: 0.105, iter iou: 0.187, epoch loss: 0.197, epoch iou: 0.137,  time cost: 51.991 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-222] LR: 0.0010: iter loss: 0.315, iter iou: 0.144, epoch loss: 0.197, epoch iou: 0.137,  time cost: 53.377 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-223] LR: 0.0010: iter loss: 0.123, iter iou: 0.144, epoch loss: 0.197, epoch iou: 0.137,  time cost: 52.105 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-224] LR: 0.0010: iter loss: 0.093, iter iou: 0.176, epoch loss: 0.196, epoch iou: 0.137,  time cost: 51.175 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-225] LR: 0.0010: iter loss: 0.052, iter iou: 0.168, epoch loss: 0.196, epoch iou: 0.137,  time cost: 51.928 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-226] LR: 0.0010: iter loss: 0.119, iter iou: 0.152, epoch loss: 0.195, epoch iou: 0.138,  time cost: 53.751 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-227] LR: 0.0010: iter loss: 0.229, iter iou: 0.138, epoch loss: 0.196, epoch iou: 0.138,  time cost: 52.239 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-228] LR: 0.0010: iter loss: 0.139, iter iou: 0.131, epoch loss: 0.195, epoch iou: 0.137,  time cost: 48.994 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-229] LR: 0.0010: iter loss: 0.078, iter iou: 0.160, epoch loss: 0.195, epoch iou: 0.138,  time cost: 51.180 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-230] LR: 0.0010: iter loss: 0.111, iter iou: 0.171, epoch loss: 0.194, epoch iou: 0.138,  time cost: 52.118 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-231] LR: 0.0010: iter loss: 0.045, iter iou: 0.153, epoch loss: 0.194, epoch iou: 0.138,  time cost: 52.256 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-232] LR: 0.0010: iter loss: 0.253, iter iou: 0.127, epoch loss: 0.194, epoch iou: 0.138,  time cost: 50.028 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-233] LR: 0.0010: iter loss: 0.122, iter iou: 0.142, epoch loss: 0.194, epoch iou: 0.138,  time cost: 51.742 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-234] LR: 0.0010: iter loss: 0.195, iter iou: 0.119, epoch loss: 0.194, epoch iou: 0.138,  time cost: 52.206 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-235] LR: 0.0010: iter loss: 0.087, iter iou: 0.165, epoch loss: 0.193, epoch iou: 0.138,  time cost: 53.506 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-236] LR: 0.0010: iter loss: 0.120, iter iou: 0.139, epoch loss: 0.193, epoch iou: 0.138,  time cost: 50.244 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-237] LR: 0.0010: iter loss: 0.139, iter iou: 0.168, epoch loss: 0.193, epoch iou: 0.138,  time cost: 51.775 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-238] LR: 0.0010: iter loss: 0.104, iter iou: 0.161, epoch loss: 0.192, epoch iou: 0.138,  time cost: 51.084 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-239] LR: 0.0010: iter loss: 0.092, iter iou: 0.160, epoch loss: 0.192, epoch iou: 0.138,  time cost: 50.511 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-240] LR: 0.0010: iter loss: 0.110, iter iou: 0.170, epoch loss: 0.192, epoch iou: 0.138,  time cost: 49.836 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-241] LR: 0.0010: iter loss: 0.084, iter iou: 0.158, epoch loss: 0.191, epoch iou: 0.138,  time cost: 51.940 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-242] LR: 0.0010: iter loss: 0.070, iter iou: 0.160, epoch loss: 0.191, epoch iou: 0.138,  time cost: 52.011 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-243] LR: 0.0010: iter loss: 0.083, iter iou: 0.165, epoch loss: 0.190, epoch iou: 0.139,  time cost: 52.462 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-244] LR: 0.0010: iter loss: 0.064, iter iou: 0.173, epoch loss: 0.190, epoch iou: 0.139,  time cost: 50.064 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-245] LR: 0.0010: iter loss: 0.124, iter iou: 0.157, epoch loss: 0.189, epoch iou: 0.139,  time cost: 54.252 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-246] LR: 0.0010: iter loss: 0.054, iter iou: 0.151, epoch loss: 0.189, epoch iou: 0.139,  time cost: 51.994 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-247] LR: 0.0010: iter loss: 0.137, iter iou: 0.134, epoch loss: 0.189, epoch iou: 0.139,  time cost: 51.957 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-248] LR: 0.0010: iter loss: 0.099, iter iou: 0.130, epoch loss: 0.188, epoch iou: 0.139,  time cost: 50.086 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-249] LR: 0.0010: iter loss: 0.102, iter iou: 0.180, epoch loss: 0.188, epoch iou: 0.139,  time cost: 50.335 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-250] LR: 0.0010: iter loss: 0.077, iter iou: 0.167, epoch loss: 0.187, epoch iou: 0.139,  time cost: 51.203 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-251] LR: 0.0010: iter loss: 0.032, iter iou: 0.180, epoch loss: 0.187, epoch iou: 0.139,  time cost: 51.558 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-252] LR: 0.0010: iter loss: 0.086, iter iou: 0.185, epoch loss: 0.186, epoch iou: 0.139,  time cost: 50.384 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-253] LR: 0.0010: iter loss: 0.084, iter iou: 0.178, epoch loss: 0.186, epoch iou: 0.140,  time cost: 50.918 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-254] LR: 0.0010: iter loss: 0.063, iter iou: 0.162, epoch loss: 0.186, epoch iou: 0.140,  time cost: 51.475 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-255] LR: 0.0010: iter loss: 0.066, iter iou: 0.184, epoch loss: 0.185, epoch iou: 0.140,  time cost: 52.055 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-256] LR: 0.0010: iter loss: 0.280, iter iou: 0.147, epoch loss: 0.185, epoch iou: 0.140,  time cost: 49.736 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-257] LR: 0.0010: iter loss: 0.079, iter iou: 0.150, epoch loss: 0.185, epoch iou: 0.140,  time cost: 53.077 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-258] LR: 0.0010: iter loss: 0.100, iter iou: 0.152, epoch loss: 0.185, epoch iou: 0.140,  time cost: 51.790 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-259] LR: 0.0010: iter loss: 0.082, iter iou: 0.151, epoch loss: 0.184, epoch iou: 0.140,  time cost: 50.792 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-260] LR: 0.0010: iter loss: 0.110, iter iou: 0.227, epoch loss: 0.184, epoch iou: 0.140,  time cost: 49.116 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-261] LR: 0.0010: iter loss: 0.076, iter iou: 0.157, epoch loss: 0.184, epoch iou: 0.140,  time cost: 51.115 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-262] LR: 0.0010: iter loss: 0.046, iter iou: 0.179, epoch loss: 0.183, epoch iou: 0.140,  time cost: 51.545 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-263] LR: 0.0010: iter loss: 0.106, iter iou: 0.173, epoch loss: 0.183, epoch iou: 0.141,  time cost: 53.289 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-264] LR: 0.0010: iter loss: 0.052, iter iou: 0.176, epoch loss: 0.182, epoch iou: 0.141,  time cost: 49.998 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-265] LR: 0.0010: iter loss: 0.084, iter iou: 0.146, epoch loss: 0.182, epoch iou: 0.141,  time cost: 51.506 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-266] LR: 0.0010: iter loss: 0.046, iter iou: 0.164, epoch loss: 0.181, epoch iou: 0.141,  time cost: 51.412 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-267] LR: 0.0010: iter loss: 0.146, iter iou: 0.141, epoch loss: 0.181, epoch iou: 0.141,  time cost: 52.878 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-268] LR: 0.0010: iter loss: 0.200, iter iou: 0.137, epoch loss: 0.181, epoch iou: 0.141,  time cost: 50.209 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-269] LR: 0.0010: iter loss: 0.055, iter iou: 0.204, epoch loss: 0.181, epoch iou: 0.141,  time cost: 54.461 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-270] LR: 0.0010: iter loss: 0.097, iter iou: 0.175, epoch loss: 0.181, epoch iou: 0.141,  time cost: 52.028 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-271] LR: 0.0010: iter loss: 0.075, iter iou: 0.158, epoch loss: 0.180, epoch iou: 0.141,  time cost: 51.078 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-272] LR: 0.0010: iter loss: 0.138, iter iou: 0.177, epoch loss: 0.180, epoch iou: 0.141,  time cost: 49.876 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-273] LR: 0.0010: iter loss: 0.142, iter iou: 0.175, epoch loss: 0.180, epoch iou: 0.142,  time cost: 52.076 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-274] LR: 0.0010: iter loss: 0.274, iter iou: 0.159, epoch loss: 0.180, epoch iou: 0.142,  time cost: 51.808 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-275] LR: 0.0010: iter loss: 0.314, iter iou: 0.186, epoch loss: 0.181, epoch iou: 0.142,  time cost: 51.838 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-276] LR: 0.0010: iter loss: 0.174, iter iou: 0.150, epoch loss: 0.181, epoch iou: 0.142,  time cost: 51.672 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-277] LR: 0.0010: iter loss: 0.072, iter iou: 0.164, epoch loss: 0.180, epoch iou: 0.142,  time cost: 52.236 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-278] LR: 0.0010: iter loss: 0.073, iter iou: 0.217, epoch loss: 0.180, epoch iou: 0.142,  time cost: 52.115 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-279] LR: 0.0010: iter loss: 0.078, iter iou: 0.202, epoch loss: 0.180, epoch iou: 0.142,  time cost: 50.473 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-280] LR: 0.0010: iter loss: 0.098, iter iou: 0.173, epoch loss: 0.179, epoch iou: 0.142,  time cost: 49.307 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-281] LR: 0.0010: iter loss: 0.147, iter iou: 0.202, epoch loss: 0.179, epoch iou: 0.143,  time cost: 51.022 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-282] LR: 0.0010: iter loss: 0.178, iter iou: 0.152, epoch loss: 0.179, epoch iou: 0.143,  time cost: 50.727 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-283] LR: 0.0010: iter loss: 0.195, iter iou: 0.149, epoch loss: 0.179, epoch iou: 0.143,  time cost: 51.315 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-284] LR: 0.0010: iter loss: 0.166, iter iou: 0.130, epoch loss: 0.179, epoch iou: 0.143,  time cost: 48.772 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-285] LR: 0.0010: iter loss: 0.164, iter iou: 0.146, epoch loss: 0.179, epoch iou: 0.143,  time cost: 51.608 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-286] LR: 0.0010: iter loss: 0.119, iter iou: 0.151, epoch loss: 0.179, epoch iou: 0.143,  time cost: 51.801 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-287] LR: 0.0010: iter loss: 0.184, iter iou: 0.158, epoch loss: 0.179, epoch iou: 0.143,  time cost: 52.224 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-288] LR: 0.0010: iter loss: 0.062, iter iou: 0.127, epoch loss: 0.179, epoch iou: 0.143,  time cost: 51.260 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-289] LR: 0.0010: iter loss: 0.058, iter iou: 0.183, epoch loss: 0.178, epoch iou: 0.143,  time cost: 51.837 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-290] LR: 0.0010: iter loss: 0.044, iter iou: 0.164, epoch loss: 0.178, epoch iou: 0.143,  time cost: 52.903 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-291] LR: 0.0010: iter loss: 0.047, iter iou: 0.158, epoch loss: 0.177, epoch iou: 0.143,  time cost: 51.582 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-292] LR: 0.0010: iter loss: 0.120, iter iou: 0.136, epoch loss: 0.177, epoch iou: 0.143,  time cost: 53.636 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-293] LR: 0.0010: iter loss: 0.129, iter iou: 0.149, epoch loss: 0.177, epoch iou: 0.143,  time cost: 52.178 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-294] LR: 0.0010: iter loss: 0.093, iter iou: 0.147, epoch loss: 0.177, epoch iou: 0.143,  time cost: 54.415 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-295] LR: 0.0010: iter loss: 0.196, iter iou: 0.138, epoch loss: 0.177, epoch iou: 0.143,  time cost: 54.168 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-296] LR: 0.0010: iter loss: 0.057, iter iou: 0.175, epoch loss: 0.176, epoch iou: 0.143,  time cost: 50.407 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-297] LR: 0.0010: iter loss: 0.083, iter iou: 0.156, epoch loss: 0.176, epoch iou: 0.143,  time cost: 51.538 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-298] LR: 0.0010: iter loss: 0.109, iter iou: 0.167, epoch loss: 0.176, epoch iou: 0.143,  time cost: 53.898 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-299] LR: 0.0010: iter loss: 0.055, iter iou: 0.122, epoch loss: 0.175, epoch iou: 0.143,  time cost: 53.186 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-300] LR: 0.0010: iter loss: 0.104, iter iou: 0.161, epoch loss: 0.175, epoch iou: 0.143,  time cost: 51.492 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-301] LR: 0.0010: iter loss: 0.103, iter iou: 0.203, epoch loss: 0.175, epoch iou: 0.143,  time cost: 50.879 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-302] LR: 0.0010: iter loss: 0.050, iter iou: 0.185, epoch loss: 0.174, epoch iou: 0.144,  time cost: 51.686 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-303] LR: 0.0010: iter loss: 0.055, iter iou: 0.165, epoch loss: 0.174, epoch iou: 0.144,  time cost: 53.820 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-304] LR: 0.0010: iter loss: 0.227, iter iou: 0.205, epoch loss: 0.174, epoch iou: 0.144,  time cost: 50.889 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-305] LR: 0.0010: iter loss: 0.110, iter iou: 0.149, epoch loss: 0.174, epoch iou: 0.144,  time cost: 52.491 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-306] LR: 0.0010: iter loss: 0.039, iter iou: 0.176, epoch loss: 0.174, epoch iou: 0.144,  time cost: 51.498 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-307] LR: 0.0010: iter loss: 0.047, iter iou: 0.175, epoch loss: 0.173, epoch iou: 0.144,  time cost: 52.741 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-308] LR: 0.0010: iter loss: 0.057, iter iou: 0.221, epoch loss: 0.173, epoch iou: 0.144,  time cost: 49.879 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-309] LR: 0.0010: iter loss: 0.074, iter iou: 0.169, epoch loss: 0.172, epoch iou: 0.144,  time cost: 52.664 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-310] LR: 0.0010: iter loss: 0.069, iter iou: 0.153, epoch loss: 0.172, epoch iou: 0.144,  time cost: 52.595 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-311] LR: 0.0010: iter loss: 0.114, iter iou: 0.139, epoch loss: 0.172, epoch iou: 0.144,  time cost: 50.905 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-312] LR: 0.0010: iter loss: 0.041, iter iou: 0.202, epoch loss: 0.171, epoch iou: 0.145,  time cost: 49.196 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-313] LR: 0.0010: iter loss: 0.174, iter iou: 0.205, epoch loss: 0.171, epoch iou: 0.145,  time cost: 51.192 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-314] LR: 0.0010: iter loss: 0.199, iter iou: 0.156, epoch loss: 0.172, epoch iou: 0.145,  time cost: 51.803 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-315] LR: 0.0010: iter loss: 0.233, iter iou: 0.177, epoch loss: 0.172, epoch iou: 0.145,  time cost: 51.770 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-316] LR: 0.0010: iter loss: 0.208, iter iou: 0.148, epoch loss: 0.172, epoch iou: 0.145,  time cost: 49.584 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-317] LR: 0.0010: iter loss: 0.125, iter iou: 0.200, epoch loss: 0.172, epoch iou: 0.145,  time cost: 51.700 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-318] LR: 0.0010: iter loss: 0.078, iter iou: 0.145, epoch loss: 0.171, epoch iou: 0.145,  time cost: 53.823 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-319] LR: 0.0010: iter loss: 0.086, iter iou: 0.151, epoch loss: 0.171, epoch iou: 0.145,  time cost: 52.076 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-320] LR: 0.0010: iter loss: 0.219, iter iou: 0.184, epoch loss: 0.171, epoch iou: 0.145,  time cost: 49.745 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-321] LR: 0.0010: iter loss: 0.050, iter iou: 0.213, epoch loss: 0.171, epoch iou: 0.145,  time cost: 51.730 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-322] LR: 0.0010: iter loss: 0.073, iter iou: 0.201, epoch loss: 0.171, epoch iou: 0.146,  time cost: 52.567 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-323] LR: 0.0010: iter loss: 0.131, iter iou: 0.227, epoch loss: 0.171, epoch iou: 0.146,  time cost: 50.799 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-324] LR: 0.0010: iter loss: 0.097, iter iou: 0.148, epoch loss: 0.170, epoch iou: 0.146,  time cost: 49.899 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-325] LR: 0.0010: iter loss: 0.100, iter iou: 0.159, epoch loss: 0.170, epoch iou: 0.146,  time cost: 51.593 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-326] LR: 0.0010: iter loss: 0.097, iter iou: 0.147, epoch loss: 0.170, epoch iou: 0.146,  time cost: 51.781 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-327] LR: 0.0010: iter loss: 0.133, iter iou: 0.155, epoch loss: 0.170, epoch iou: 0.146,  time cost: 52.323 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-328] LR: 0.0010: iter loss: 0.241, iter iou: 0.209, epoch loss: 0.170, epoch iou: 0.146,  time cost: 49.762 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-329] LR: 0.0010: iter loss: 0.092, iter iou: 0.156, epoch loss: 0.170, epoch iou: 0.146,  time cost: 51.734 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-330] LR: 0.0010: iter loss: 0.043, iter iou: 0.228, epoch loss: 0.169, epoch iou: 0.146,  time cost: 51.387 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-331] LR: 0.0010: iter loss: 0.165, iter iou: 0.149, epoch loss: 0.169, epoch iou: 0.146,  time cost: 54.367 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-332] LR: 0.0010: iter loss: 0.087, iter iou: 0.161, epoch loss: 0.169, epoch iou: 0.146,  time cost: 50.002 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-333] LR: 0.0010: iter loss: 0.079, iter iou: 0.188, epoch loss: 0.169, epoch iou: 0.147,  time cost: 50.846 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-334] LR: 0.0010: iter loss: 0.058, iter iou: 0.200, epoch loss: 0.168, epoch iou: 0.147,  time cost: 50.834 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-335] LR: 0.0010: iter loss: 0.217, iter iou: 0.128, epoch loss: 0.169, epoch iou: 0.147,  time cost: 52.013 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-336] LR: 0.0010: iter loss: 0.109, iter iou: 0.164, epoch loss: 0.168, epoch iou: 0.147,  time cost: 50.420 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-337] LR: 0.0010: iter loss: 0.068, iter iou: 0.163, epoch loss: 0.168, epoch iou: 0.147,  time cost: 53.107 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-338] LR: 0.0010: iter loss: 0.046, iter iou: 0.167, epoch loss: 0.168, epoch iou: 0.147,  time cost: 53.254 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-339] LR: 0.0010: iter loss: 0.121, iter iou: 0.151, epoch loss: 0.168, epoch iou: 0.147,  time cost: 53.356 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-340] LR: 0.0010: iter loss: 0.202, iter iou: 0.157, epoch loss: 0.168, epoch iou: 0.147,  time cost: 49.424 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-341] LR: 0.0010: iter loss: 0.196, iter iou: 0.141, epoch loss: 0.168, epoch iou: 0.147,  time cost: 51.608 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-342] LR: 0.0010: iter loss: 0.069, iter iou: 0.173, epoch loss: 0.168, epoch iou: 0.147,  time cost: 51.614 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-343] LR: 0.0010: iter loss: 0.076, iter iou: 0.212, epoch loss: 0.167, epoch iou: 0.147,  time cost: 50.771 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-344] LR: 0.0010: iter loss: 0.081, iter iou: 0.184, epoch loss: 0.167, epoch iou: 0.147,  time cost: 49.303 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-345] LR: 0.0010: iter loss: 0.106, iter iou: 0.160, epoch loss: 0.167, epoch iou: 0.147,  time cost: 51.450 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-346] LR: 0.0010: iter loss: 0.092, iter iou: 0.161, epoch loss: 0.167, epoch iou: 0.147,  time cost: 51.520 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-347] LR: 0.0010: iter loss: 0.060, iter iou: 0.192, epoch loss: 0.166, epoch iou: 0.147,  time cost: 51.283 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-348] LR: 0.0010: iter loss: 0.046, iter iou: 0.183, epoch loss: 0.166, epoch iou: 0.148,  time cost: 48.987 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-349] LR: 0.0010: iter loss: 0.247, iter iou: 0.156, epoch loss: 0.166, epoch iou: 0.148,  time cost: 51.124 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-350] LR: 0.0010: iter loss: 0.099, iter iou: 0.222, epoch loss: 0.166, epoch iou: 0.148,  time cost: 51.179 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-351] LR: 0.0010: iter loss: 0.050, iter iou: 0.191, epoch loss: 0.166, epoch iou: 0.148,  time cost: 50.892 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-352] LR: 0.0010: iter loss: 0.037, iter iou: 0.231, epoch loss: 0.165, epoch iou: 0.148,  time cost: 48.471 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-353] LR: 0.0010: iter loss: 0.051, iter iou: 0.167, epoch loss: 0.165, epoch iou: 0.148,  time cost: 51.831 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-354] LR: 0.0010: iter loss: 0.039, iter iou: 0.217, epoch loss: 0.165, epoch iou: 0.148,  time cost: 50.612 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-355] LR: 0.0010: iter loss: 0.188, iter iou: 0.147, epoch loss: 0.165, epoch iou: 0.148,  time cost: 51.340 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-356] LR: 0.0010: iter loss: 0.053, iter iou: 0.152, epoch loss: 0.164, epoch iou: 0.148,  time cost: 50.889 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-357] LR: 0.0010: iter loss: 0.056, iter iou: 0.176, epoch loss: 0.164, epoch iou: 0.148,  time cost: 52.085 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-358] LR: 0.0010: iter loss: 0.093, iter iou: 0.183, epoch loss: 0.164, epoch iou: 0.149,  time cost: 51.728 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-359] LR: 0.0010: iter loss: 0.045, iter iou: 0.185, epoch loss: 0.164, epoch iou: 0.149,  time cost: 51.878 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-360] LR: 0.0010: iter loss: 0.073, iter iou: 0.218, epoch loss: 0.163, epoch iou: 0.149,  time cost: 50.176 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-361] LR: 0.0010: iter loss: 0.054, iter iou: 0.176, epoch loss: 0.163, epoch iou: 0.149,  time cost: 51.626 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-362] LR: 0.0010: iter loss: 0.059, iter iou: 0.167, epoch loss: 0.163, epoch iou: 0.149,  time cost: 51.664 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-363] LR: 0.0010: iter loss: 0.074, iter iou: 0.200, epoch loss: 0.162, epoch iou: 0.149,  time cost: 53.228 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-364] LR: 0.0010: iter loss: 0.055, iter iou: 0.209, epoch loss: 0.162, epoch iou: 0.149,  time cost: 50.352 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-365] LR: 0.0010: iter loss: 0.041, iter iou: 0.250, epoch loss: 0.162, epoch iou: 0.150,  time cost: 50.541 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-366] LR: 0.0010: iter loss: 0.060, iter iou: 0.168, epoch loss: 0.162, epoch iou: 0.150,  time cost: 53.047 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-367] LR: 0.0010: iter loss: 0.062, iter iou: 0.161, epoch loss: 0.161, epoch iou: 0.150,  time cost: 52.255 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-368] LR: 0.0010: iter loss: 0.061, iter iou: 0.185, epoch loss: 0.161, epoch iou: 0.150,  time cost: 49.827 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-369] LR: 0.0010: iter loss: 0.086, iter iou: 0.191, epoch loss: 0.161, epoch iou: 0.150,  time cost: 51.287 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-370] LR: 0.0010: iter loss: 0.148, iter iou: 0.173, epoch loss: 0.161, epoch iou: 0.150,  time cost: 52.781 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-371] LR: 0.0010: iter loss: 0.271, iter iou: 0.129, epoch loss: 0.161, epoch iou: 0.150,  time cost: 51.852 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-372] LR: 0.0010: iter loss: 0.146, iter iou: 0.138, epoch loss: 0.161, epoch iou: 0.150,  time cost: 49.595 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-373] LR: 0.0010: iter loss: 0.155, iter iou: 0.191, epoch loss: 0.161, epoch iou: 0.150,  time cost: 51.596 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-374] LR: 0.0010: iter loss: 0.164, iter iou: 0.189, epoch loss: 0.161, epoch iou: 0.150,  time cost: 51.566 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-375] LR: 0.0010: iter loss: 0.091, iter iou: 0.215, epoch loss: 0.161, epoch iou: 0.150,  time cost: 50.633 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-376] LR: 0.0010: iter loss: 0.102, iter iou: 0.185, epoch loss: 0.161, epoch iou: 0.150,  time cost: 49.285 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-377] LR: 0.0010: iter loss: 0.079, iter iou: 0.179, epoch loss: 0.160, epoch iou: 0.150,  time cost: 53.615 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-378] LR: 0.0010: iter loss: 0.044, iter iou: 0.209, epoch loss: 0.160, epoch iou: 0.151,  time cost: 52.328 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-379] LR: 0.0010: iter loss: 0.054, iter iou: 0.213, epoch loss: 0.160, epoch iou: 0.151,  time cost: 51.581 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-380] LR: 0.0010: iter loss: 0.065, iter iou: 0.210, epoch loss: 0.160, epoch iou: 0.151,  time cost: 50.478 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-381] LR: 0.0010: iter loss: 0.227, iter iou: 0.170, epoch loss: 0.160, epoch iou: 0.151,  time cost: 51.898 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-382] LR: 0.0010: iter loss: 0.079, iter iou: 0.193, epoch loss: 0.160, epoch iou: 0.151,  time cost: 52.146 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-383] LR: 0.0010: iter loss: 0.042, iter iou: 0.219, epoch loss: 0.159, epoch iou: 0.151,  time cost: 51.949 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-384] LR: 0.0010: iter loss: 0.185, iter iou: 0.136, epoch loss: 0.159, epoch iou: 0.151,  time cost: 50.325 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-385] LR: 0.0010: iter loss: 0.042, iter iou: 0.167, epoch loss: 0.159, epoch iou: 0.151,  time cost: 51.857 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-386] LR: 0.0010: iter loss: 0.049, iter iou: 0.162, epoch loss: 0.159, epoch iou: 0.151,  time cost: 50.918 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-387] LR: 0.0010: iter loss: 0.226, iter iou: 0.140, epoch loss: 0.159, epoch iou: 0.151,  time cost: 51.410 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-388] LR: 0.0010: iter loss: 0.040, iter iou: 0.195, epoch loss: 0.159, epoch iou: 0.151,  time cost: 49.973 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-389] LR: 0.0010: iter loss: 0.039, iter iou: 0.213, epoch loss: 0.158, epoch iou: 0.151,  time cost: 50.858 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-390] LR: 0.0010: iter loss: 0.194, iter iou: 0.172, epoch loss: 0.158, epoch iou: 0.152,  time cost: 51.983 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-391] LR: 0.0010: iter loss: 0.054, iter iou: 0.209, epoch loss: 0.158, epoch iou: 0.152,  time cost: 51.747 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-392] LR: 0.0010: iter loss: 0.043, iter iou: 0.174, epoch loss: 0.158, epoch iou: 0.152,  time cost: 49.629 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-393] LR: 0.0010: iter loss: 0.069, iter iou: 0.158, epoch loss: 0.158, epoch iou: 0.152,  time cost: 51.977 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-394] LR: 0.0010: iter loss: 0.066, iter iou: 0.181, epoch loss: 0.157, epoch iou: 0.152,  time cost: 51.499 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-395] LR: 0.0010: iter loss: 0.097, iter iou: 0.152, epoch loss: 0.157, epoch iou: 0.152,  time cost: 51.537 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-396] LR: 0.0010: iter loss: 0.064, iter iou: 0.194, epoch loss: 0.157, epoch iou: 0.152,  time cost: 49.548 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-397] LR: 0.0010: iter loss: 0.324, iter iou: 0.148, epoch loss: 0.157, epoch iou: 0.152,  time cost: 51.456 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-398] LR: 0.0010: iter loss: 0.126, iter iou: 0.159, epoch loss: 0.157, epoch iou: 0.152,  time cost: 52.477 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-399] LR: 0.0010: iter loss: 0.077, iter iou: 0.209, epoch loss: 0.157, epoch iou: 0.152,  time cost: 51.276 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-400] LR: 0.0010: iter loss: 0.064, iter iou: 0.177, epoch loss: 0.157, epoch iou: 0.152,  time cost: 50.002 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-401] LR: 0.0010: iter loss: 0.065, iter iou: 0.169, epoch loss: 0.157, epoch iou: 0.152,  time cost: 52.326 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-402] LR: 0.0010: iter loss: 0.046, iter iou: 0.204, epoch loss: 0.156, epoch iou: 0.152,  time cost: 52.640 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-403] LR: 0.0010: iter loss: 0.048, iter iou: 0.174, epoch loss: 0.156, epoch iou: 0.152,  time cost: 52.276 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-404] LR: 0.0010: iter loss: 0.217, iter iou: 0.200, epoch loss: 0.156, epoch iou: 0.152,  time cost: 51.690 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-405] LR: 0.0010: iter loss: 0.073, iter iou: 0.207, epoch loss: 0.156, epoch iou: 0.153,  time cost: 52.792 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-406] LR: 0.0010: iter loss: 0.157, iter iou: 0.234, epoch loss: 0.156, epoch iou: 0.153,  time cost: 52.193 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-407] LR: 0.0010: iter loss: 0.076, iter iou: 0.164, epoch loss: 0.156, epoch iou: 0.153,  time cost: 51.295 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-408] LR: 0.0010: iter loss: 0.204, iter iou: 0.233, epoch loss: 0.156, epoch iou: 0.153,  time cost: 49.958 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-409] LR: 0.0010: iter loss: 0.060, iter iou: 0.168, epoch loss: 0.156, epoch iou: 0.153,  time cost: 52.348 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-410] LR: 0.0010: iter loss: 0.102, iter iou: 0.202, epoch loss: 0.156, epoch iou: 0.153,  time cost: 52.380 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-411] LR: 0.0010: iter loss: 0.132, iter iou: 0.160, epoch loss: 0.156, epoch iou: 0.153,  time cost: 52.402 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-412] LR: 0.0010: iter loss: 0.077, iter iou: 0.248, epoch loss: 0.155, epoch iou: 0.153,  time cost: 50.535 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-413] LR: 0.0010: iter loss: 0.067, iter iou: 0.167, epoch loss: 0.155, epoch iou: 0.153,  time cost: 52.058 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-414] LR: 0.0010: iter loss: 0.084, iter iou: 0.234, epoch loss: 0.155, epoch iou: 0.154,  time cost: 52.463 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-415] LR: 0.0010: iter loss: 0.107, iter iou: 0.177, epoch loss: 0.155, epoch iou: 0.154,  time cost: 52.337 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-416] LR: 0.0010: iter loss: 0.032, iter iou: 0.220, epoch loss: 0.155, epoch iou: 0.154,  time cost: 50.502 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-417] LR: 0.0010: iter loss: 0.058, iter iou: 0.164, epoch loss: 0.154, epoch iou: 0.154,  time cost: 51.619 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-418] LR: 0.0010: iter loss: 0.071, iter iou: 0.155, epoch loss: 0.154, epoch iou: 0.154,  time cost: 51.869 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-419] LR: 0.0010: iter loss: 0.054, iter iou: 0.167, epoch loss: 0.154, epoch iou: 0.154,  time cost: 70.048 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-420] LR: 0.0010: iter loss: 0.088, iter iou: 0.153, epoch loss: 0.154, epoch iou: 0.154,  time cost: 50.170 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-421] LR: 0.0010: iter loss: 0.082, iter iou: 0.169, epoch loss: 0.154, epoch iou: 0.154,  time cost: 53.997 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-422] LR: 0.0010: iter loss: 0.082, iter iou: 0.164, epoch loss: 0.153, epoch iou: 0.154,  time cost: 52.801 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-423] LR: 0.0010: iter loss: 0.141, iter iou: 0.177, epoch loss: 0.153, epoch iou: 0.154,  time cost: 52.109 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-424] LR: 0.0010: iter loss: 0.061, iter iou: 0.227, epoch loss: 0.153, epoch iou: 0.154,  time cost: 50.150 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-425] LR: 0.0010: iter loss: 0.163, iter iou: 0.171, epoch loss: 0.153, epoch iou: 0.154,  time cost: 51.878 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-426] LR: 0.0010: iter loss: 0.057, iter iou: 0.206, epoch loss: 0.153, epoch iou: 0.154,  time cost: 51.995 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-427] LR: 0.0010: iter loss: 0.097, iter iou: 0.261, epoch loss: 0.153, epoch iou: 0.155,  time cost: 51.533 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-428] LR: 0.0010: iter loss: 0.063, iter iou: 0.153, epoch loss: 0.153, epoch iou: 0.155,  time cost: 49.764 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-429] LR: 0.0010: iter loss: 0.024, iter iou: 0.184, epoch loss: 0.152, epoch iou: 0.155,  time cost: 52.050 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-430] LR: 0.0010: iter loss: 0.082, iter iou: 0.197, epoch loss: 0.152, epoch iou: 0.155,  time cost: 52.323 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-431] LR: 0.0010: iter loss: 0.063, iter iou: 0.218, epoch loss: 0.152, epoch iou: 0.155,  time cost: 52.199 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n","[Epoch-0 Iter-432] LR: 0.0010: iter loss: 0.137, iter iou: 0.161, epoch loss: 0.152, epoch iou: 0.155,  time cost: 50.327 s\n","torch.Size([2, 8, 256, 768])\n","torch.Size([393216, 8])\n","torch.Size([393216])\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 5))\n","plt.suptitle('dice loss + cross-entropy training')\n","plt.subplot(1, 2, 1)\n","plt.plot(loss_plot)\n","plt.ylabel('loss')\n","plt.xlabel('iteration')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(iou_plot)\n","plt.ylabel('Image-IoU (%)')\n","plt.xlabel('iteration')"],"metadata":{"id":"qE_1dpNRcsVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(net.state_dict(), \"result.pt\")"],"metadata":{"id":"4SzUTrZYZzMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(net.state_dict(), \n","                    pjoin(cfg.WEIGHTS_SAVE_ROOT, \"weights_ep_%d_%.3f_%.3f.pth\" \n","                            % (epoch, epoch_loss / epoch_size, epoch_miou / epoch_size)))"],"metadata":{"id":"OQmsLOcbaiXL"},"execution_count":null,"outputs":[]}]}